{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e4db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamilah\\Documents\\Github_analysis_PROJECTS\\Time_series_analysis\\Motor_classification\\Motor_classification\\c_calculate_metrics\\put_scalar_trialdata_into_pandas.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  dat = np.array(dat)\n",
      "C:\\Users\\jamilah\\Documents\\Github_analysis_PROJECTS\\Time_series_analysis\\Motor_classification\\Motor_classification\\c_calculate_metrics\\put_scalar_trialdata_into_pandas.py:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X = np.array(X)\n",
      "C:\\Users\\jamilah\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload \n",
    "# %autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import zip_longest\n",
    "\n",
    "varr = {}\n",
    "varr['main_path'] = \"C:\\\\Users\\\\jamilah\\\\Documents\\\\Github_analysis_PROJECTS\\\\Time_series_analysis\\\\Motor_classification\\\\Motor_classification\"  \n",
    "varr['main_path1'] = \"%s\\\\a_data_standardization\" % (varr['main_path'])\n",
    "varr['main_path2'] = \"%s\\\\b_data_preprocessing\" % (varr['main_path'])\n",
    "varr['main_path3'] = \"%s\\\\c_calculate_metrics\" % (varr['main_path'])\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '%s' % (varr['main_path']))\n",
    "\n",
    "\n",
    "from c_calculate_metrics.put_scalar_trialdata_into_pandas import *\n",
    "from c_calculate_metrics.put_timeseries_trialdata_into_pandas import *\n",
    "\n",
    "from subfunctions.make_a_properlist import *\n",
    "from subfunctions.confidence_interval import *\n",
    "from subfunctions.two_sample_stats import *\n",
    "from subfunctions.semi_automated_gen import *\n",
    "from subfunctions.my_dropna_python import *\n",
    "from subfunctions.compare_condi import compare_across_condi, compare_within_condi\n",
    "\n",
    "df_scalarmetics_exp = put_scalar_trialdata_into_pandas(varr)\n",
    "df_timeseries_exp = put_timeseries_trialdata_into_pandas(varr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697b08f",
   "metadata": {},
   "source": [
    "# Testing if data is correct : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ae53af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df_scalarmetics_exp[rot] :  (442, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>tr</th>\n",
       "      <th>ss</th>\n",
       "      <th>ax</th>\n",
       "      <th>new3_ind_st</th>\n",
       "      <th>new3_ind_end</th>\n",
       "      <th>trnum_org</th>\n",
       "      <th>SSQ_b4</th>\n",
       "      <th>SSQ_af</th>\n",
       "      <th>SSQ_diff</th>\n",
       "      <th>FRT_em</th>\n",
       "      <th>res_type</th>\n",
       "      <th>TR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>5066</td>\n",
       "      <td>5252</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "      <td>[2, 3, 2, 5]</td>\n",
       "      <td>[-2, -2, -2, -4]</td>\n",
       "      <td>3.908</td>\n",
       "      <td>7</td>\n",
       "      <td>18.499999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5627</td>\n",
       "      <td>5790</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "      <td>[2, 3, 2, 5]</td>\n",
       "      <td>[-2, -2, -2, -4]</td>\n",
       "      <td>2.66</td>\n",
       "      <td>7</td>\n",
       "      <td>16.199999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>5974</td>\n",
       "      <td>6136</td>\n",
       "      <td>33.0</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "      <td>[2, 3, 2, 5]</td>\n",
       "      <td>[-2, -2, -2, -4]</td>\n",
       "      <td>1.668</td>\n",
       "      <td>6</td>\n",
       "      <td>16.100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6141</td>\n",
       "      <td>6367</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "      <td>[2, 3, 2, 5]</td>\n",
       "      <td>[-2, -2, -2, -4]</td>\n",
       "      <td>8.04</td>\n",
       "      <td>10</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>7475</td>\n",
       "      <td>7643</td>\n",
       "      <td>41.0</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "      <td>[2, 3, 2, 5]</td>\n",
       "      <td>[-2, -2, -2, -4]</td>\n",
       "      <td>5.256</td>\n",
       "      <td>7</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject  tr  ss ax new3_ind_st new3_ind_end trnum_org        SSQ_b4  \\\n",
       "437      17  16  -1  2        5066         5252      28.0  [0, 1, 0, 1]   \n",
       "438      17  17   2  0        5627         5790      31.0  [0, 1, 0, 1]   \n",
       "439      17  18  -2  0        5974         6136      33.0  [0, 1, 0, 1]   \n",
       "440      17  19   0  1        6141         6367      34.0  [0, 1, 0, 1]   \n",
       "441      17  20  -1  0        7475         7643      41.0  [0, 1, 0, 1]   \n",
       "\n",
       "           SSQ_af          SSQ_diff FRT_em res_type         TR  \n",
       "437  [2, 3, 2, 5]  [-2, -2, -2, -4]  3.908        7  18.499999  \n",
       "438  [2, 3, 2, 5]  [-2, -2, -2, -4]   2.66        7  16.199999  \n",
       "439  [2, 3, 2, 5]  [-2, -2, -2, -4]  1.668        6  16.100001  \n",
       "440  [2, 3, 2, 5]  [-2, -2, -2, -4]   8.04       10        7.8  \n",
       "441  [2, 3, 2, 5]  [-2, -2, -2, -4]  5.256        7       16.7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape of df_scalarmetics_exp[rot] : ', df_scalarmetics_exp['rot'].shape)\n",
    "df_scalarmetics_exp['rot'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb98394",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of df_scalarmetics_exp[trans] : ', df_scalarmetics_exp['trans'].shape)\n",
    "df_scalarmetics_exp['trans'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e84471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df_timeseries_exp[rot] :  (86006, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>tr</th>\n",
       "      <th>ss</th>\n",
       "      <th>ax</th>\n",
       "      <th>dp</th>\n",
       "      <th>time</th>\n",
       "      <th>res_type</th>\n",
       "      <th>SIGCOM_ax0</th>\n",
       "      <th>SIGCOM_ax1</th>\n",
       "      <th>SIGCOM_ax2</th>\n",
       "      <th>SIG_ax0</th>\n",
       "      <th>SIG_ax1</th>\n",
       "      <th>SIG_ax2</th>\n",
       "      <th>JOY_ax0</th>\n",
       "      <th>JOY_ax1</th>\n",
       "      <th>JOY_ax2</th>\n",
       "      <th>NOISE_ax0</th>\n",
       "      <th>NOISE_ax1</th>\n",
       "      <th>NOISE_ax2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86001</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.453208</td>\n",
       "      <td>0.804159</td>\n",
       "      <td>-4.699437</td>\n",
       "      <td>-1.514817</td>\n",
       "      <td>0.803347</td>\n",
       "      <td>-4.719625</td>\n",
       "      <td>0.301392</td>\n",
       "      <td>-0.082375</td>\n",
       "      <td>-4.927108</td>\n",
       "      <td>0.850650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.927108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86002</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.391906</td>\n",
       "      <td>0.804159</td>\n",
       "      <td>-4.699425</td>\n",
       "      <td>-1.461697</td>\n",
       "      <td>0.803352</td>\n",
       "      <td>-4.719593</td>\n",
       "      <td>0.333524</td>\n",
       "      <td>-0.082369</td>\n",
       "      <td>-4.917930</td>\n",
       "      <td>0.902199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.917930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86003</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>16.500001</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.313130</td>\n",
       "      <td>0.804159</td>\n",
       "      <td>-4.699425</td>\n",
       "      <td>-1.382446</td>\n",
       "      <td>0.807940</td>\n",
       "      <td>-4.719292</td>\n",
       "      <td>0.356304</td>\n",
       "      <td>-0.086946</td>\n",
       "      <td>-4.908213</td>\n",
       "      <td>0.953649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.908213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86004</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>16.599999</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.221655</td>\n",
       "      <td>0.804159</td>\n",
       "      <td>-4.699425</td>\n",
       "      <td>-1.284506</td>\n",
       "      <td>0.807370</td>\n",
       "      <td>-4.719829</td>\n",
       "      <td>0.362870</td>\n",
       "      <td>-0.089799</td>\n",
       "      <td>-4.897957</td>\n",
       "      <td>1.004994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.897957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86005</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.125844</td>\n",
       "      <td>0.804159</td>\n",
       "      <td>-4.699425</td>\n",
       "      <td>-1.179229</td>\n",
       "      <td>0.805081</td>\n",
       "      <td>-4.719719</td>\n",
       "      <td>0.364322</td>\n",
       "      <td>-0.088796</td>\n",
       "      <td>-4.887165</td>\n",
       "      <td>1.056230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.887165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject    tr   ss   ax     dp       time  res_type  SIGCOM_ax0  \\\n",
       "86001     17.0  20.0 -1.0  0.0  163.0  16.300000       7.0   -1.453208   \n",
       "86002     17.0  20.0 -1.0  0.0  164.0  16.400000       7.0   -1.391906   \n",
       "86003     17.0  20.0 -1.0  0.0  165.0  16.500001       7.0   -1.313130   \n",
       "86004     17.0  20.0 -1.0  0.0  166.0  16.599999       7.0   -1.221655   \n",
       "86005     17.0  20.0 -1.0  0.0  167.0  16.700000       7.0   -1.125844   \n",
       "\n",
       "       SIGCOM_ax1  SIGCOM_ax2   SIG_ax0   SIG_ax1   SIG_ax2   JOY_ax0  \\\n",
       "86001    0.804159   -4.699437 -1.514817  0.803347 -4.719625  0.301392   \n",
       "86002    0.804159   -4.699425 -1.461697  0.803352 -4.719593  0.333524   \n",
       "86003    0.804159   -4.699425 -1.382446  0.807940 -4.719292  0.356304   \n",
       "86004    0.804159   -4.699425 -1.284506  0.807370 -4.719829  0.362870   \n",
       "86005    0.804159   -4.699425 -1.179229  0.805081 -4.719719  0.364322   \n",
       "\n",
       "        JOY_ax1   JOY_ax2  NOISE_ax0  NOISE_ax1  NOISE_ax2  \n",
       "86001 -0.082375 -4.927108   0.850650        0.0  -4.927108  \n",
       "86002 -0.082369 -4.917930   0.902199        0.0  -4.917930  \n",
       "86003 -0.086946 -4.908213   0.953649        0.0  -4.908213  \n",
       "86004 -0.089799 -4.897957   1.004994        0.0  -4.897957  \n",
       "86005 -0.088796 -4.887165   1.056230        0.0  -4.887165  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape of df_timeseries_exp[rot] : ', df_timeseries_exp['rot'].shape)\n",
    "df_timeseries_exp['rot'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of df_timeseries_exp[trans] : ', df_timeseries_exp['trans'].shape)\n",
    "df_timeseries_exp['trans'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_stats(incon, inner_name_list, outer_name_list, ax_all_vals, outer2_name, cou, final_temp):\n",
    "\n",
    "    num_of_tests = 2\n",
    "    rshift = 0.12\n",
    "    \n",
    "    # Vector retrival\n",
    "    for i in range(len(outer_name_list)):\n",
    "        vec[i] = semi_automated_gen(incon, outer_name_list[i], ax_all_vals, inner_name_list, outer_name_list)\n",
    "    \n",
    "    # Statistical tests\n",
    "    df_res = two_sample_stats(vec[0], vec[1], num_of_tests)\n",
    "    \n",
    "    # Saving stats in a DataFrame\n",
    "    col0 = pd.Series('%s %s %s' % (outer2_name, incon, outer_name_list))  # string\n",
    "    temp_cur = pd.concat([col0, df_res], axis=1)\n",
    "    final_temp = pd.concat([temp_cur, final_temp], axis=0)\n",
    "    \n",
    "    # Plotting stars\n",
    "    marg = 2\n",
    "    if df_res.pval_1.to_numpy()[0] < 0.0167 and df_res.pval_2.to_numpy()[0] < 0.0167:\n",
    "        row_ind = [i for i in range(len(inner_name_list)) if incon == inner_name_list[i]][0]\n",
    "        ax[cou-1].text(row_ind-rshift, np.sum(vec[0])+marg, \"*\", fontsize=22)\n",
    "        ax[cou].text(row_ind-rshift, np.sum(vec[1])+marg, \"*\", fontsize=22)\n",
    "        \n",
    "    return final_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8921a55d",
   "metadata": {},
   "source": [
    "# Original Count plot only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c08736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redoing the count bargraph because I can not go back to it and make changes fast; it is too complex\n",
    "final_temp_withincondi = pd.DataFrame()\n",
    "\n",
    "final_temp_acrosscondi = pd.DataFrame()\n",
    "\n",
    "df_long_tot = pd.DataFrame()\n",
    "\n",
    "outer3_name = ['rot', 'trans']\n",
    "\n",
    "bonfero_thresh = 0.0167\n",
    "across_marg = 4\n",
    "\n",
    "# estimator_type = 'sum'\n",
    "estimator_type = 'mean' \n",
    "\n",
    "df_sig_cats = pd.DataFrame()\n",
    "\n",
    "num_of_tests = 2\n",
    "\n",
    "\n",
    "\n",
    "for exp in range(2):\n",
    "    if exp == 0:\n",
    "        exp_name = 'Rotation'\n",
    "        anom = 'RO', 'PI', 'YA'\n",
    "    else:\n",
    "        exp_name = 'Translation'\n",
    "        anom = 'LR', 'FB', 'UD'\n",
    "        \n",
    "    df = df_scalarmetics_exp[outer3_name[exp]]\n",
    "    \n",
    "    outer_name_list = ['sub', 'sup']\n",
    "    inner_name_list = ['IC', 'EC', 'NC', 'NR']\n",
    "\n",
    "    fig, ax = plt.subplots(2, 6, figsize=(20,10))\n",
    "    po = 0\n",
    "    cou = 0\n",
    "    \n",
    "    ax_all_vals_exp = []\n",
    "    \n",
    "    for i in range(3):  # 0=RO/LR, 1=PI/FB, 2=YA/UD\n",
    "        \n",
    "        ax_all_vals = []\n",
    "        for j in range(1,3):  # 1=sub, 2=sup\n",
    "            \n",
    "            \n",
    "            num_of_sub = len(df.subject.value_counts().to_numpy())\n",
    "            print('num_of_sub: ', num_of_sub)\n",
    "            \n",
    "            # 1a) I need the counts per subject to get the population count for the error bars\n",
    "            IC_vals = list(df.subject[(df.res_type == 1) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            \n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp0_0 = list(df.subject[(df.res_type == 2) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp0_1 = list(df.subject[(df.res_type == 4) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp0_2 = list(df.subject[(df.res_type == 5) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            add1st = [x + y for x, y in zip_longest(temp0_0, temp0_1, fillvalue=0)]\n",
    "            EC_vals = [x + y for x, y in zip_longest(add1st, temp0_2, fillvalue=0)]\n",
    "\n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp1_0 = list(df.subject[(df.res_type == 3) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp1_1 = list(df.subject[(df.res_type == 6) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp1_2 = list(df.subject[(df.res_type == 7) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            add1st = [x + y for x, y in zip_longest(temp1_0, temp1_1, fillvalue=0)]\n",
    "            NC_vals = [x + y for x, y in zip_longest(add1st, temp1_2, fillvalue=0)]\n",
    "\n",
    "            NR_vals = df.subject[(df.res_type == 9) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy()\n",
    "            \n",
    "            print('IC_vals : ', IC_vals)\n",
    "            print('EC_vals : ', EC_vals)\n",
    "            print('NC_vals : ', NC_vals)\n",
    "            print('NR_vals : ', NR_vals)\n",
    "            \n",
    "            # Check for correctness : the sum of IC+EC+NC+NR == IC_vals+EC_vals+NC_vals+NR_vals\n",
    "            sumofvals = np.sum(IC_vals) + np.sum(EC_vals) + np.sum(NC_vals) + np.sum(NR_vals)\n",
    "            # print('sumofvals : ', sumofvals)\n",
    "\n",
    "            # ----------------\n",
    "\n",
    "            # 3) Normalize/scale the counts to values that it would be at if NO TRIALS were removed \n",
    "            \n",
    "            # Each subject should have 42 trials : \n",
    "            # 3axis*2sub/sup*2direction (practice) +  3axis*2sub/sup*2direction (2times) + 6 sham = 12 + 24 + 6\n",
    "            # 12+24=36/6 plotting categories(axis subORsup) = 6\n",
    "            # so each axis subORsup should have 6 trials, not counting the 6 sham\n",
    "            suspose2be_counts = num_of_sub*6 \n",
    "            # print('suspose2be_counts : ', suspose2be_counts)\n",
    "\n",
    "            multfactor = suspose2be_counts/sumofvals\n",
    "\n",
    "            nor_IC_vals = [multfactor*i for i in IC_vals]\n",
    "            nor_EC_vals = [multfactor*i for i in EC_vals]\n",
    "            nor_NC_vals = [multfactor*i for i in NC_vals]\n",
    "            nor_NR_vals = [multfactor*i for i in NR_vals]\n",
    "            \n",
    "            print('nor_IC_vals : ', nor_IC_vals)\n",
    "            print('nor_EC_vals : ', nor_EC_vals)\n",
    "            print('nor_NC_vals : ', nor_NC_vals)\n",
    "            print('nor_NR_vals : ', nor_NR_vals)\n",
    "\n",
    "            # ----------------\n",
    "\n",
    "            # Make a new dataFrame with all the vals in one column and the label in the other put vals in a nested array\n",
    "            all_vals = [nor_IC_vals, nor_EC_vals, nor_NC_vals, nor_NR_vals]\n",
    "            longcol_num = []\n",
    "            longcol_text = []\n",
    "            for n1 in range(len(all_vals)):\n",
    "                for n2 in range(len(all_vals[n1])):\n",
    "                    longcol_num.append(all_vals[n1][n2])\n",
    "                    longcol_text.append(inner_name_list[n1])\n",
    "\n",
    "            col0 = pd.Series(np.ravel(longcol_text))\n",
    "            col1 = pd.Series(np.ravel(longcol_num))\n",
    "            temp = pd.concat([col0, col1], axis=1)\n",
    "            df_long = temp.rename({0: 'str', 1: 'vals'}, axis=1)\n",
    "            \n",
    "            \n",
    "            # Make an appended df_long across all conditions for statistical processing\n",
    "            df_long_copy = temp.rename({0: 'str_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1]), 1: 'vals_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1])}, axis=1)\n",
    "            df_long_tot = pd.concat([df_long_tot, df_long_copy], axis=1)\n",
    "            # ----------------\n",
    "            \n",
    "            # Plot each subORsup per axis (for now)\n",
    "            # sns.set(font_scale = 1.7, style=\"white\", palette=None) \n",
    "            # OR\n",
    "            sns.set(font_scale = 2) # default is without style and palette\n",
    "            \n",
    "            sns.color_palette(\"light:#90a4ae\", as_cmap=True)  # Greys_d, light:#5A9\n",
    "            \n",
    "            \n",
    "            if estimator_type == 'mean':\n",
    "                # Plot the mean trial count\n",
    "                if i == 0:\n",
    "                    sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[po,cou], ci=\"sd\", capsize=.2, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=\"#3E26A8\", linewidth=3, edgecolor=\"#3E26A8\")\n",
    "                elif i == 1:\n",
    "                    sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[po,cou], ci=\"sd\", capsize=.2, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=\"#02BAC3\", linewidth=3, edgecolor=\"#02BAC3\")\n",
    "                elif i == 2:\n",
    "                    sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[po,cou], ci=\"sd\", capsize=.2, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=\"#F6EF1F\", linewidth=3, edgecolor=\"#F6EF1F\")\n",
    "                ax[po,cou].set(ylim=(0, 25))\n",
    "                ax[po,0].set_ylabel('Normalized mean trial count (%s)' % (exp_name), fontsize=22)\n",
    "            elif estimator_type == 'sum':\n",
    "                # Plot the sum trial count\n",
    "                if i == 0:\n",
    "                    sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[po,cou], ci=\"sd\", capsize=.2, estimator=np.sum, palette=\"light:#90a4ae\", errcolor=\"#3E26A8\", linewidth=3, edgecolor=\"#3E26A8\")\n",
    "                elif i == 1:\n",
    "                    sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[po,cou], ci=\"sd\", capsize=.2, estimator=np.sum, palette=\"light:#90a4ae\", errcolor=\"#02BAC3\", linewidth=3, edgecolor=\"#02BAC3\")\n",
    "                elif i == 2:\n",
    "                    sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[po,cou], ci=\"sd\", capsize=.2, estimator=np.sum, palette=\"light:#90a4ae\", errcolor=\"#F6EF1F\", linewidth=3, edgecolor=\"#F6EF1F\")\n",
    "                ax[po,cou].set(ylim=(0, 110))\n",
    "                ax[po,0].set_ylabel('Normalized trial count (%s)' % (exp_name), fontsize=22)\n",
    "            \n",
    "            if cou > 0:\n",
    "                ax[po,cou].set_ylabel(' ')\n",
    "                ax[po,cou].set_yticks([])\n",
    "            \n",
    "            if j == 1:\n",
    "                ax[po,cou].set_xlabel('%s sub' % (anom[i]), fontsize=22)\n",
    "            elif j == 2:\n",
    "                ax[po,cou].set_xlabel('%s sup' % (anom[i]), fontsize=22)\n",
    "                \n",
    "            ax_all_vals.append(all_vals)\n",
    "            \n",
    "            # ----------------\n",
    "            # Forgot about this code : to plot only categories above the 95%CI\n",
    "            # ----------------\n",
    "            if cou == 1 or cou == 3 or cou == 5:\n",
    "                ax_all_vals = np.array(ax_all_vals)\n",
    "                print('length of ax_all_vals : ', ax_all_vals.shape)\n",
    "                vec = make_a_properlist(np.concatenate((ax_all_vals[0], ax_all_vals[1]), axis=0))\n",
    "                mean_dat, lower_tail, upper_tail = confidence_interval(vec, desired_CI=0.95)\n",
    "                ax[po,cou-1].axhline(lower_tail, ls='--', linewidth=2, color='r')\n",
    "                ax[po,cou].axhline(lower_tail, ls='--', linewidth=2, color='r')\n",
    "                \n",
    "            \n",
    "                # Save which categories that are greater than the 95% lower CI for time response plotting\n",
    "                \n",
    "                # do not include NR: does not make sense to show response time for people who never \n",
    "                # responded (NR should all be around 15-16 seconds)\n",
    "                for q in range(len(inner_name_list)-1):\n",
    "                    for rr in range(2):\n",
    "                        if np.sum(ax_all_vals[rr][q]) > lower_tail:\n",
    "                            col4 = pd.Series(1) # number\n",
    "                        else:\n",
    "                            col4 = pd.Series(0) # number\n",
    "                        col0 = pd.Series(outer3_name[exp])  # string\n",
    "                        col1 = pd.Series(anom[i])  # string\n",
    "                        col2 = pd.Series(outer_name_list[rr]) # string\n",
    "                        col3 = pd.Series(inner_name_list[q])  # string\n",
    "                        temp = pd.concat([col0, col1, col2, col3, col4], axis=1)\n",
    "                        df_sig_cats = pd.concat([temp, df_sig_cats], axis=0)\n",
    "            # ----------------           \n",
    "            \n",
    "            cou = cou + 1\n",
    "            plt.xticks(fontsize=22)\n",
    "            \n",
    "    \n",
    "    # ----------------\n",
    "    # Statistics\n",
    "    # ----------------\n",
    "    # Trying a different way : because across conditions need all the data\n",
    "    # 1) put needed data in a DataFrame, 2) read from DataFrame and do stats at the end:\n",
    "    if exp == 0:\n",
    "        # Within axes : differences with axis across same condition (Visually looked for any combinations) \n",
    "        which_anom = 'RO'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        vec0 = df_long_tot.vals_rot_RO_sub[(df_long_tot.str_rot_RO_sub == incon)].to_numpy()\n",
    "        print('vec0 : ', vec0)\n",
    "        vec1 = df_long_tot.vals_rot_RO_sup[(df_long_tot.str_rot_RO_sup == incon)].to_numpy()\n",
    "        print('vec1 : ', vec1)\n",
    "\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "\n",
    "        which_anom = 'PI'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "\n",
    "        which_anom = 'YA'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "\n",
    "        # ---------\n",
    "\n",
    "        # Across axes : differences between axis but same condition (Visually looked for any combinations)\n",
    "        incon = 'IC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'EC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'NC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        # ---------\n",
    "\n",
    "        incon = 'IC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'EC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'NC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "    elif exp == 1:\n",
    "        # Within axes : differences with axis across same condition (Visually looked for any combinations) \n",
    "        which_anom = 'LR'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "\n",
    "        which_anom = 'FB'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "\n",
    "        which_anom = 'UD'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, exp, which_anom, estimator_type)\n",
    "\n",
    "        # ---------\n",
    "\n",
    "        # Across axes : differences between axis but same condition (Visually looked for any combinations)\n",
    "        incon = 'IC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'EC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'NC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        # ---------\n",
    "\n",
    "        incon = 'IC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'EC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        incon = 'NC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, po, ss, exp, estimator_type)\n",
    "\n",
    "        plt.xticks(fontsize=22)\n",
    "            \n",
    " \n",
    "    plt.savefig('counts_%s.png' % (exp_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5fe4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "incon = 'IC'\n",
    "vec1 = df_long_tot.vals_rot_YA_sub[(df_long_tot.str_rot_YA_sub == incon)].to_numpy()\n",
    "print('vec1 : ', vec1)\n",
    "vec2 = df_long_tot.vals_rot_YA_sup[(df_long_tot.str_rot_YA_sup == incon)].to_numpy()\n",
    "print('vec2 : ', vec2)\n",
    "df_res = two_sample_stats(vec1, vec2, num_of_tests)\n",
    "df_res\n",
    "Dstat, pval_2 = stats.ranksums(vec1, vec2)\n",
    "print('pval_2 : ', pval_2)\n",
    "\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pad vector with nan\n",
    "if len(vec1) > len(vec2):\n",
    "    longSIG = vec1\n",
    "    shortSIG = vec2\n",
    "    flag = 0\n",
    "else: \n",
    "    shortSIG = vec1\n",
    "    longSIG = vec2\n",
    "    flag = 1\n",
    "\n",
    "print('length of longSIG : ', len(longSIG))\n",
    "\n",
    "\n",
    "# Reassign\n",
    "if flag == 0:\n",
    "    vec1 = longSIG\n",
    "    vec2 = make_a_properlist(fix_shSIG)\n",
    "elif flag == 1:\n",
    "    vec1 = make_a_properlist(fix_shSIG)\n",
    "    vec2 = longSIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c649912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1628bb",
   "metadata": {},
   "source": [
    "# Original TR plot only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_temp_withincondi = pd.DataFrame()\n",
    "final_temp_acrosscondi = pd.DataFrame()\n",
    "\n",
    "df_long_tot = pd.DataFrame()\n",
    "\n",
    "outer3_name = ['rot', 'trans']\n",
    "\n",
    "estimator_type = 'mean'\n",
    "bonfero_thresh = 0.0167\n",
    "across_marg = 4\n",
    "\n",
    "num_of_tests = 2\n",
    "\n",
    "\n",
    "for exp in range(2):\n",
    "    if exp == 0:\n",
    "        exp_name = 'Rotation'\n",
    "        anom = 'RO', 'PI', 'YA'\n",
    "    else:\n",
    "        exp_name = 'Translation'\n",
    "        anom = 'LR', 'FB', 'UD'\n",
    "        \n",
    "    df = df_scalarmetics_exp[outer3_name[exp]]\n",
    "    \n",
    "    outer_name_list = ['sub', 'sup']\n",
    "    inner_name_list = ['IC', 'EC', 'NC', 'NR']\n",
    "\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(20,10))\n",
    "    cou = 0\n",
    "    \n",
    "    ax_all_vals_exp = []\n",
    "    for i in range(3):  # 0=RO/LR, 1=PI/FB, 2=YA/UD\n",
    "        print('axis: ', i)\n",
    "        \n",
    "        ax_all_vals = []\n",
    "        for j in range(1,3):  # 1=sub, 2=sup\n",
    "            print('sub/sup: ', j)\n",
    "            \n",
    "            num_of_sub = len(df.subject.value_counts().to_numpy())\n",
    "            # print('num_of_sub: ', num_of_sub)\n",
    "\n",
    "            # 1a) I need the counts per subject to get the population count for the error bars\n",
    "            IC_vals = list(df.TR[(df.res_type == 1) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            \n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp0_0 = list(df.TR[(df.res_type == 2) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=2: ', temp0_0)\n",
    "            temp0_1 = list(df.TR[(df.res_type == 4) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=4: ', temp0_1)\n",
    "            temp0_2 = list(df.TR[(df.res_type == 5) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=5: ', temp0_2)\n",
    "            \n",
    "            applist = temp0_0, temp0_1, temp0_2\n",
    "            EC_vals = make_a_properlist(applist)\n",
    "            print('EC_vals: ', EC_vals)\n",
    "\n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp1_0 = list(df.TR[(df.res_type == 3) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=3: ', temp1_0)\n",
    "            temp1_1 = list(df.TR[(df.res_type == 6) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=6: ', temp1_1)\n",
    "            temp1_2 = list(df.TR[(df.res_type == 7) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=7: ', temp1_2)\n",
    "            \n",
    "            applist = temp1_0, temp1_1, temp1_2\n",
    "            NC_vals = make_a_properlist(applist)\n",
    "            print('NC_vals: ', NC_vals)\n",
    "            \n",
    "            # No Response is zero or nan because there was no response : do not even include it in the final plot\n",
    "            # NR_vals = df.TR[(df.res_type == 9) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy()\n",
    "            \n",
    "            # Put desired values in a DataFrame\n",
    "            # all_vals = [IC_vals, EC_vals, NC_vals, NR_vals]\n",
    "            all_vals = [IC_vals, EC_vals, NC_vals]\n",
    "            longcol_num = []\n",
    "            longcol_text = []\n",
    "            for n1 in range(len(all_vals)):\n",
    "                for n2 in range(len(all_vals[n1])):\n",
    "                    longcol_num.append(all_vals[n1][n2])\n",
    "                    longcol_text.append(inner_name_list[n1])\n",
    "\n",
    "            col0 = pd.Series(np.ravel(longcol_text))\n",
    "            col1 = pd.Series(np.ravel(longcol_num))\n",
    "            temp = pd.concat([col0, col1], axis=1)\n",
    "            df_long = temp.rename({0: 'str', 1: 'vals'}, axis=1)\n",
    "            \n",
    "            # Make an appended df_long across all conditions for statistical processing\n",
    "            df_long_copy = temp.rename({0: 'str_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1]), 1: 'vals_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1])}, axis=1)\n",
    "            df_long_tot = pd.concat([df_long_tot, df_long_copy], axis=1)\n",
    "            # ----------------\n",
    "            \n",
    "            # Plot each subORsup per axis (for now)\n",
    "            # sns.set(font_scale = 1.7, style=\"white\", palette=None) \n",
    "            # OR\n",
    "            sns.set(font_scale = 2) # default is without style and palette\n",
    "            \n",
    "            sns.color_palette(\"light:#90a4ae\", as_cmap=True)  # Greys_d, light:#5A9\n",
    "            \n",
    "            if i == 0:\n",
    "                sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[cou], ci=\"sd\", capsize=.2, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=\"#3E26A8\", linewidth=3, edgecolor=\"#3E26A8\")\n",
    "            elif i == 1:\n",
    "                sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[cou], ci=\"sd\", capsize=.2, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=\"#02BAC3\", linewidth=3, edgecolor=\"#02BAC3\")\n",
    "            elif i == 2:\n",
    "                sns.barplot(x=\"str\", y=\"vals\", data=df_long, ax=ax[cou], ci=\"sd\", capsize=.2, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=\"#F6EF1F\", linewidth=3, edgecolor=\"#F6EF1F\")\n",
    "            ax[cou].set(ylim=(0, 35))\n",
    "            \n",
    "            # ax[0].set_ylabel('Normalized trial count (%s)' % (exp_name))\n",
    "            ax[0].set_ylabel('Mean RT (%s)' % (exp_name), fontsize=22)\n",
    "            \n",
    "            plt.xticks(fontsize=22)\n",
    "            \n",
    "            if cou > 0:\n",
    "                ax[cou].set_ylabel(' ')\n",
    "                ax[cou].set_yticks([])\n",
    "            \n",
    "            if j == 1:\n",
    "                ax[cou].set_xlabel('%s sub' % (anom[i]), fontsize=22)\n",
    "            elif j == 2:\n",
    "                ax[cou].set_xlabel('%s sup' % (anom[i]), fontsize=22)\n",
    "                \n",
    "            ax_all_vals.append(all_vals)\n",
    "            \n",
    "            cou = cou + 1\n",
    "            \n",
    "            \n",
    "    # ----------------\n",
    "    # Statistics\n",
    "    # ----------------\n",
    "    # Trying a different way : because across conditions need all the data\n",
    "    # 1) put needed data in a DataFrame, 2) read from DataFrame and do stats at the end:\n",
    "    if exp == 0:\n",
    "        # Within axes : differences with axis across same condition (Visually looked for any combinations) \n",
    "        which_anom = 'RO'\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        \n",
    "        which_anom = 'PI'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        \n",
    "        which_anom = 'YA'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        \n",
    "        \n",
    "        # Across axes : differences between axis but same condition (Visually looked for any combinations)\n",
    "        incon = 'IC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "        incon = 'EC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "        incon = 'NC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "    elif exp == 1:\n",
    "        # Within axes : differences with axis across same condition (Visually looked for any combinations) \n",
    "        which_anom = 'LR'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, exp, which_anom, estimator_type)\n",
    "        \n",
    "        which_anom = 'FB'\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        \n",
    "        which_anom = 'UD'\n",
    "        incon = 'IC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        incon = 'EC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        incon = 'NC'\n",
    "        print(exp, which_anom, incon)\n",
    "        final_temp_withincondi = compare_within_condi(df_long_tot, incon, num_of_tests, final_temp_withincondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax,  exp, which_anom, estimator_type)\n",
    "        \n",
    "        # Across axes : differences between axis but same condition (Visually looked for any combinations)\n",
    "        incon = 'IC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "        incon = 'EC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "        incon = 'NC'\n",
    "        ss = 'sub'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "        incon = 'EC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "        incon = 'NC'\n",
    "        ss = 'sup'\n",
    "        print(exp, ss, incon)\n",
    "        final_temp_acrosscondi = compare_across_condi(df_long_tot, incon, num_of_tests, final_temp_acrosscondi, bonfero_thresh, inner_name_list, across_marg, outer_name_list, anom, ax, ss, exp, estimator_type)\n",
    "        \n",
    "    plt.savefig('TR_%s.png' % (exp_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625a795",
   "metadata": {},
   "source": [
    "# Combined Count plot with TR plot\n",
    "**Remember to run the cell twice, for the background of the plot and text to appear correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48483f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subfunctions.plot_TR2subplot import *\n",
    "from subfunctions.plot_count2subplot2 import *\n",
    "\n",
    "dfexp_count_acrosscondi = pd.DataFrame()\n",
    "dfexp_count_withincondi = pd.DataFrame()\n",
    "\n",
    "dfexp_TR_acrosscondi = pd.DataFrame()\n",
    "dfexp_TR_withincondi = pd.DataFrame()\n",
    "\n",
    "eval_axis_dir = 'neg_ax'  # 'all_ax' = combine negative and positive axes, 'pos_ax' = positive axes only, 'neg_ax' = negative axes only\n",
    "\n",
    "for exp in range(2):\n",
    "    if exp == 0:\n",
    "        exp_name = 'Rotation'\n",
    "        anom = 'RO', 'PI', 'YA'\n",
    "    else:\n",
    "        exp_name = 'Translation'\n",
    "        anom = 'LR', 'FB', 'UD'\n",
    "\n",
    "    fig, ax = plt.subplots(3, 6, figsize=(20,10))\n",
    "    po = 0\n",
    "    cou = 0\n",
    "    estimator_type = 'sum'\n",
    "    %time cou, count_acrosscondi, count_withincondi, df_long_tot_count = plot_count2subplot2(po, df_scalarmetics_exp, cou, ax, plt, exp, exp_name, anom, estimator_type, eval_axis_dir)\n",
    "    po = 1\n",
    "    cou = 0\n",
    "    estimator_type = 'mean'\n",
    "    cou, count_acrosscondi, count_withincondi, df_long_tot_count = plot_count2subplot2(po, df_scalarmetics_exp, cou, ax, plt, exp, exp_name, anom, estimator_type, eval_axis_dir)\n",
    "    po = 2\n",
    "    cou = 0\n",
    "    TR_acrosscondi, TR_withincondi, df_long_tot_TR = plot_TR2subplot(po, df_scalarmetics_exp, cou, ax, plt, exp, exp_name, anom, eval_axis_dir)\n",
    "    \n",
    "    # Stack both rot and trans into shared dataframes\n",
    "    dfexp_count_acrosscondi = pd.concat([dfexp_count_acrosscondi, count_acrosscondi], axis=0)\n",
    "    dfexp_count_withincondi = pd.concat([dfexp_count_withincondi, count_withincondi], axis=0)\n",
    "    dfexp_TR_acrosscondi = pd.concat([dfexp_TR_acrosscondi, TR_acrosscondi], axis=0)\n",
    "    dfexp_TR_withincondi = pd.concat([dfexp_TR_withincondi, TR_withincondi], axis=0)\n",
    "    \n",
    "    plt.savefig('counts_tr_%s_%s.png' % (exp_name, eval_axis_dir))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for normalized count mean : this plot is what people are used to using \n",
    "# for evaluating error bars\n",
    "from subfunctions.plot_count2subplot2 import *\n",
    "\n",
    "dfexp_mean_count_acrosscondi = pd.DataFrame()\n",
    "dfexp_mean_count_withincondi = pd.DataFrame()\n",
    "\n",
    "estimator_type = 'mean'\n",
    "\n",
    "eval_axis_dir = 'all_ax'  # 'all_ax' = combine negative and positive axes, 'all_ax' = positive axes only, 'neg_ax' = negative axes only\n",
    "\n",
    "fig, ax = plt.subplots(2, 6, figsize=(20,10))\n",
    "po = 0\n",
    "cou = 0\n",
    "for exp in range(2):\n",
    "    if exp == 0:\n",
    "        exp_name = 'Rotation'\n",
    "        anom = 'RO', 'PI', 'YA'\n",
    "    else:\n",
    "        exp_name = 'Translation'\n",
    "        anom = 'LR', 'FB', 'UD'\n",
    "\n",
    "    cou, count_acrosscondi, count_withincondi, df_long_tot_mean_count = plot_count2subplot2(po, df_scalarmetics_exp, cou, ax, plt, exp, exp_name, anom, estimator_type, eval_axis_dir)\n",
    "    po = po + 1\n",
    "    cou = 0\n",
    "    \n",
    "    # Stack both rot and trans into shared dataframes\n",
    "    dfexp_mean_count_acrosscondi = pd.concat([dfexp_mean_count_acrosscondi, count_acrosscondi], axis=0)\n",
    "    dfexp_mean_count_withincondi = pd.concat([dfexp_mean_count_withincondi, count_withincondi], axis=0)\n",
    "    \n",
    "plt.savefig('meancounts_tr_RotTrans.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d60906",
   "metadata": {},
   "source": [
    "# Record count and TR statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record count statistics for within condition (axis) : single star\n",
    "dfexp_count_acrosscondi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a71a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double star\n",
    "dfexp_count_withincondi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_TR_acrosscondi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_TR_withincondi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_mean_count_acrosscondi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ef818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_mean_count_withincondi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e2a8a",
   "metadata": {},
   "source": [
    "# Redoing Statistics so that they are more aligned with motion detection literature: group IC+EC and group NC+NR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1159ead1",
   "metadata": {},
   "source": [
    "## Compare across all axes for Rotation and Translation AND condensed Rotation and Translation figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c797e5",
   "metadata": {},
   "source": [
    "### Get count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cffa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(df, df_long_tot, anom, outer3_name, outer_name_list):\n",
    "    \n",
    "    for i in range(3):\n",
    "        ax_all_vals = []\n",
    "        for j in range(1,3):  # 1=sub, 2=sup\n",
    "\n",
    "            num_of_sub = len(df.subject.value_counts().to_numpy())\n",
    "            print('num_of_sub: ', num_of_sub)\n",
    "\n",
    "            # 1a) I need the counts per subject to get the population count for the error bars\n",
    "            IC_vals = list(df.subject[(df.res_type == 1) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "\n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp0_0 = list(df.subject[(df.res_type == 2) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp0_1 = list(df.subject[(df.res_type == 4) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp0_2 = list(df.subject[(df.res_type == 5) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            add1st = [x + y for x, y in zip_longest(temp0_0, temp0_1, fillvalue=0)]\n",
    "            EC_vals = [x + y for x, y in zip_longest(add1st, temp0_2, fillvalue=0)]\n",
    "\n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp1_0 = list(df.subject[(df.res_type == 3) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp1_1 = list(df.subject[(df.res_type == 6) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            temp1_2 = list(df.subject[(df.res_type == 7) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy())\n",
    "            add1st = [x + y for x, y in zip_longest(temp1_0, temp1_1, fillvalue=0)]\n",
    "            NC_vals = [x + y for x, y in zip_longest(add1st, temp1_2, fillvalue=0)]\n",
    "\n",
    "            NR_vals = df.subject[(df.res_type == 9) & (df.ax == i) & (np.abs(df.ss) == j)].value_counts().to_numpy()\n",
    "\n",
    "            print('IC_vals : ', IC_vals)\n",
    "            print('EC_vals : ', EC_vals)\n",
    "            print('NC_vals : ', NC_vals)\n",
    "            print('NR_vals : ', NR_vals)\n",
    "\n",
    "            # Check for correctness : the sum of IC+EC+NC+NR == IC_vals+EC_vals+NC_vals+NR_vals\n",
    "            sumofvals = np.sum(IC_vals) + np.sum(EC_vals) + np.sum(NC_vals) + np.sum(NR_vals)\n",
    "            # print('sumofvals : ', sumofvals)\n",
    "\n",
    "            # ----------------\n",
    "\n",
    "            # 3) Normalize/scale the counts to values that it would be at if NO TRIALS were removed \n",
    "\n",
    "            # Each subject should have 42 trials : \n",
    "            # 3axis*2sub/sup*2direction (practice) +  3axis*2sub/sup*2direction (2times) + 6 sham = 12 + 24 + 6\n",
    "            # 12+24=36/6 plotting categories(axis subORsup) = 6\n",
    "            # so each axis subORsup should have 6 trials, not counting the 6 sham\n",
    "            suspose2be_counts = num_of_sub*6 \n",
    "            # print('suspose2be_counts : ', suspose2be_counts)\n",
    "\n",
    "            multfactor = suspose2be_counts/sumofvals\n",
    "\n",
    "            nor_IC_vals = [multfactor*i for i in IC_vals]\n",
    "            nor_EC_vals = [multfactor*i for i in EC_vals]\n",
    "            nor_NC_vals = [multfactor*i for i in NC_vals]\n",
    "            nor_NR_vals = [multfactor*i for i in NR_vals]\n",
    "\n",
    "            print('nor_IC_vals : ', nor_IC_vals)\n",
    "            print('nor_EC_vals : ', nor_EC_vals)\n",
    "            print('nor_NC_vals : ', nor_NC_vals)\n",
    "            print('nor_NR_vals : ', nor_NR_vals)\n",
    "\n",
    "            # ----------------\n",
    "\n",
    "            # Make a new dataFrame with all the vals in one column and the label in the other put vals in a nested array\n",
    "            all_vals = [nor_IC_vals, nor_EC_vals, nor_NC_vals, nor_NR_vals]\n",
    "            print('all_vals : ', all_vals)\n",
    "            \n",
    "            longcol_num = []\n",
    "            longcol_text = []\n",
    "            for n1 in range(len(all_vals)):\n",
    "                for n2 in range(len(all_vals[n1])):\n",
    "                    longcol_num.append(all_vals[n1][n2])\n",
    "                    longcol_text.append(inner_name_list[n1])\n",
    "            \n",
    "            \n",
    "            col0 = pd.Series(np.ravel(longcol_text))\n",
    "            col1 = pd.Series(np.ravel(longcol_num))\n",
    "            \n",
    "            #print('col0 : ', col0)\n",
    "            #print('col1 : ', col1)\n",
    "            \n",
    "            temp = pd.concat([col0, col1], axis=1)\n",
    "            #df_long = temp.rename({0: 'str', 1: 'vals'}, axis=1)\n",
    "\n",
    "\n",
    "            # Make an appended df_long across all conditions for statistical processing\n",
    "            df_long_copy = temp.rename({0: 'str_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1]), 1: 'vals_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1])}, axis=1)\n",
    "            df_long_tot = pd.concat([df_long_tot, df_long_copy], axis=1)\n",
    "            # ----------------\n",
    "\n",
    "    return df_long_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TR(df, df_long_tot, anom, outer3_name, outer_name_list):\n",
    "    \n",
    "    for i in range(3):\n",
    "        ax_all_vals = []\n",
    "        for j in range(1,3):  # 1=sub, 2=sup\n",
    "\n",
    "            num_of_sub = len(df.subject.value_counts().to_numpy())\n",
    "            print('num_of_sub: ', num_of_sub)\n",
    "            \n",
    "            # ------------------------------------\n",
    "            # Combined axis direction evaluation \n",
    "            # ------------------------------------\n",
    "            # 1a) I need the counts per subject to get the population count for the error bars\n",
    "            IC_vals = list(df.TR[(df.res_type == 1) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "                \n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp0_0 = list(df.TR[(df.res_type == 2) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=2: ', temp0_0)\n",
    "            temp0_1 = list(df.TR[(df.res_type == 4) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=4: ', temp0_1)\n",
    "            temp0_2 = list(df.TR[(df.res_type == 5) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=5: ', temp0_2)\n",
    "\n",
    "            applist = temp0_0, temp0_1, temp0_2\n",
    "            EC_vals = make_a_properlist(applist)\n",
    "            print('EC_vals: ', EC_vals)\n",
    "\n",
    "            # More than one or category requires that you sum the entries\n",
    "            temp1_0 = list(df.TR[(df.res_type == 3) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=3: ', temp1_0)\n",
    "            temp1_1 = list(df.TR[(df.res_type == 6) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=6: ', temp1_1)\n",
    "            temp1_2 = list(df.TR[(df.res_type == 7) & (df.ax == i) & (np.abs(df.ss) == j)].to_numpy())\n",
    "            print('res_type=7: ', temp1_2)\n",
    "\n",
    "            applist = temp1_0, temp1_1, temp1_2\n",
    "            NC_vals = make_a_properlist(applist)\n",
    "            print('NC_vals: ', NC_vals)\n",
    "            \n",
    "            # Put desired values in a DataFrame\n",
    "            # all_vals = [IC_vals, EC_vals, NC_vals, NR_vals]\n",
    "            all_vals = [IC_vals, EC_vals, NC_vals]\n",
    "            longcol_num = []\n",
    "            longcol_text = []\n",
    "            for n1 in range(len(all_vals)):\n",
    "                for n2 in range(len(all_vals[n1])):\n",
    "                    longcol_num.append(all_vals[n1][n2])\n",
    "                    longcol_text.append(inner_name_list[n1])\n",
    "\n",
    "            col0 = pd.Series(np.ravel(longcol_text))\n",
    "            col1 = pd.Series(np.ravel(longcol_num))\n",
    "            \n",
    "            temp = pd.concat([col0, col1], axis=1)\n",
    "            \n",
    "            # Make an appended df_long across all conditions for statistical processing\n",
    "            df_long_copy = temp.rename({0: 'str_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1]), 1: 'vals_%s_%s_%s' % (outer3_name[exp], anom[i], outer_name_list[j-1])}, axis=1)\n",
    "            df_long_tot = pd.concat([df_long_tot, df_long_copy], axis=1)\n",
    "            # ----------------\n",
    "\n",
    "    return df_long_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b83ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_long_tot = pd.DataFrame()\n",
    "\n",
    "df_long_totTR = pd.DataFrame()\n",
    "\n",
    "outer3_name = ['rot', 'trans']\n",
    "outer_name_list = ['sub', 'sup']\n",
    "inner_name_list = ['IC', 'EC', 'NC', 'NR']\n",
    "\n",
    "\n",
    "exp = 0\n",
    "exp_name = 'Rotation'\n",
    "anom = 'RO', 'PI', 'YA'\n",
    "df = df_scalarmetics_exp[outer3_name[exp]]\n",
    "\n",
    "# counts\n",
    "df_long_tot = get_counts(df, df_long_tot, anom, outer3_name, outer_name_list)\n",
    "\n",
    "# TR\n",
    "df_long_totTR = get_TR(df, df_long_totTR, anom, outer3_name, outer_name_list)\n",
    "# -----------------------------------\n",
    "    \n",
    "exp = 1\n",
    "exp_name = 'Translation'\n",
    "anom = 'LR', 'FB', 'UD'\n",
    "df = df_scalarmetics_exp[outer3_name[exp]]\n",
    "\n",
    "# counts\n",
    "df_long_tot = get_counts(df, df_long_tot, anom, outer3_name, outer_name_list)\n",
    "\n",
    "# TR\n",
    "df_long_totTR = get_TR(df, df_long_totTR, anom, outer3_name, outer_name_list)\n",
    "\n",
    "# Rotation has 4 more participants than Translation : We compare the two without adjusting \n",
    "# Translation because we compare the distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a1d3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_long_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55da0dc",
   "metadata": {},
   "source": [
    "### Statistics of count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics count : comparing speed categories within axis : using IC+EC sub vs IC+EC sup\n",
    "num_of_tests = 2\n",
    "final_temp_acrosscondi_subsup = pd.DataFrame()\n",
    "\n",
    "inc1 = 'IC'\n",
    "inc2 = 'EC'\n",
    "\n",
    "incon_list = ['IC+EC', 'NC+NR']\n",
    "\n",
    "nom = ['RO', 'PI', 'YA', 'LR', 'FB', 'UD']\n",
    "\n",
    "for incon in incon_list:\n",
    "    for inom in nom:\n",
    "\n",
    "        if inom == 'RO':\n",
    "            vecA = df_long_tot.vals_rot_RO_sub[(df_long_tot.str_rot_RO_sub == inc1) | (df_long_tot.str_rot_RO_sub == inc2)].to_numpy()\n",
    "            vecB = df_long_tot.vals_rot_RO_sup[(df_long_tot.str_rot_RO_sup == inc1) | (df_long_tot.str_rot_RO_sup == inc2)].to_numpy()\n",
    "        elif inom == 'PI':\n",
    "            vecA = df_long_tot.vals_rot_PI_sub[(df_long_tot.str_rot_PI_sub == inc1) | (df_long_tot.str_rot_PI_sub == inc2)].to_numpy()\n",
    "            vecB = df_long_tot.vals_rot_PI_sup[(df_long_tot.str_rot_PI_sup == inc1) | (df_long_tot.str_rot_PI_sup == inc2)].to_numpy()\n",
    "        elif inom == 'YA':\n",
    "            vecA = df_long_tot.vals_rot_YA_sub[(df_long_tot.str_rot_YA_sub == inc1) | (df_long_tot.str_rot_YA_sub == inc2)].to_numpy()\n",
    "            vecB = df_long_tot.vals_rot_YA_sup[(df_long_tot.str_rot_YA_sup == inc1) | (df_long_tot.str_rot_YA_sup == inc2)].to_numpy()\n",
    "        elif inom == 'LR':\n",
    "            vecA = df_long_tot.vals_trans_LR_sub[(df_long_tot.str_trans_LR_sub == inc1) | (df_long_tot.str_trans_LR_sub == inc2)].to_numpy()\n",
    "            vecB = df_long_tot.vals_trans_LR_sup[(df_long_tot.str_trans_LR_sup == inc1) | (df_long_tot.str_trans_LR_sup == inc2)].to_numpy()\n",
    "        elif inom == 'FB':\n",
    "            vecA = df_long_tot.vals_trans_FB_sub[(df_long_tot.str_trans_FB_sub == inc1) | (df_long_tot.str_trans_FB_sub == inc2)].to_numpy()\n",
    "            vecB = df_long_tot.vals_trans_FB_sup[(df_long_tot.str_trans_FB_sup == inc1) | (df_long_tot.str_trans_FB_sup == inc2)].to_numpy()\n",
    "        elif inom == 'UD':\n",
    "            vecA = df_long_tot.vals_trans_UD_sub[(df_long_tot.str_trans_UD_sub == inc1) | (df_long_tot.str_trans_UD_sub == inc2)].to_numpy()\n",
    "            vecB = df_long_tot.vals_trans_UD_sup[(df_long_tot.str_trans_UD_sup == inc1) | (df_long_tot.str_trans_UD_sup == inc2)].to_numpy()\n",
    "\n",
    "        # Statistical tests\n",
    "        df_res = two_sample_stats(vecA, vecB, num_of_tests)\n",
    "        compare_name = '%s %s sub sup' % (incon, inom)\n",
    "        # Saving stats in a DataFrame\n",
    "        col0 = pd.Series('%s' % (compare_name))  # string\n",
    "        temp_cur = pd.concat([col0, df_res], axis=1)\n",
    "        final_temp_acrosscondi_subsup = pd.concat([temp_cur, final_temp_acrosscondi_subsup], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e330213",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_temp_acrosscondi_subsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a379a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics count : comparing across axes with respect to same speed category\n",
    "\n",
    "nom = ['RO', 'PI', 'YA', 'LR', 'FB', 'UD']\n",
    "\n",
    "num_of_tests = 2\n",
    "final_temp_acrosscondi = pd.DataFrame()\n",
    "\n",
    "incon_list = ['IC+EC', 'NC+NR']\n",
    "\n",
    "for incon in incon_list:\n",
    "    if incon == 'IC+EC':\n",
    "        inc1 = 'IC'\n",
    "        inc2 = 'EC'\n",
    "    elif incon == 'NC+NR':\n",
    "        inc1 = 'NC'\n",
    "        inc2 = 'NR'\n",
    "    \n",
    "    for ss in outer_name_list:\n",
    "        if ss == 'sub':\n",
    "            vec0 = df_long_tot.vals_rot_RO_sub[(df_long_tot.str_rot_RO_sub == inc1) | (df_long_tot.str_rot_RO_sub == inc2)].to_numpy()\n",
    "            vec1 = df_long_tot.vals_rot_PI_sub[(df_long_tot.str_rot_PI_sub == inc1) | (df_long_tot.str_rot_PI_sub == inc2)].to_numpy()\n",
    "            vec2 = df_long_tot.vals_rot_YA_sub[(df_long_tot.str_rot_YA_sub == inc1) | (df_long_tot.str_rot_YA_sub == inc2)].to_numpy()\n",
    "            vec3 = df_long_tot.vals_trans_LR_sub[(df_long_tot.str_trans_LR_sub == inc1) | (df_long_tot.str_trans_LR_sub == inc2)].to_numpy()\n",
    "            vec4 = df_long_tot.vals_trans_FB_sub[(df_long_tot.str_trans_FB_sub == inc1) | (df_long_tot.str_trans_FB_sub == inc2)].to_numpy()\n",
    "            vec5 = df_long_tot.vals_trans_UD_sub[(df_long_tot.str_trans_UD_sub == inc1) | (df_long_tot.str_trans_UD_sub == inc2)].to_numpy()  \n",
    "        elif ss == 'sup':\n",
    "            vec0 = df_long_tot.vals_rot_RO_sup[(df_long_tot.str_rot_RO_sup == inc1) | (df_long_tot.str_rot_RO_sup == inc2)].to_numpy()\n",
    "            vec1 = df_long_tot.vals_rot_PI_sup[(df_long_tot.str_rot_PI_sup == inc1) | (df_long_tot.str_rot_PI_sup == inc2)].to_numpy()\n",
    "            vec2 = df_long_tot.vals_rot_YA_sup[(df_long_tot.str_rot_YA_sup == inc1) | (df_long_tot.str_rot_YA_sup == inc2)].to_numpy()\n",
    "            vec3 = df_long_tot.vals_trans_LR_sup[(df_long_tot.str_trans_LR_sup == inc1) | (df_long_tot.str_trans_LR_sup == inc2)].to_numpy()\n",
    "            vec4 = df_long_tot.vals_trans_FB_sup[(df_long_tot.str_trans_FB_sup == inc1) | (df_long_tot.str_trans_FB_sup == inc2)].to_numpy()\n",
    "            vec5 = df_long_tot.vals_trans_UD_sup[(df_long_tot.str_trans_UD_sup == inc1) | (df_long_tot.str_trans_UD_sup == inc2)].to_numpy()\n",
    "            \n",
    "        vec_comp = [vec0, vec1, vec2, vec3, vec4, vec5]\n",
    "        \n",
    "        \n",
    "        # Statistics \n",
    "        lister = list(range(len(vec_comp)-1, 0, -1))\n",
    "        # print('lister : ', lister)\n",
    "        acc4res = len(lister)-1      # account for resets\n",
    "        tot = np.sum(lister)\n",
    "        # print('tot : ', tot)\n",
    "\n",
    "        frt = 0\n",
    "        sec = frt+1\n",
    "        c = 0\n",
    "        for i in range(tot+acc4res):\n",
    "            print('i : ', i)\n",
    "            if c < lister[frt]:\n",
    "\n",
    "                vecA = vec_comp[frt]\n",
    "                vecB = vec_comp[sec]\n",
    "                print('vecA : ', vecA)\n",
    "                print('vecB : ', vecB)\n",
    "\n",
    "                # Statistical tests\n",
    "                df_res = two_sample_stats(vecA, vecB, num_of_tests)\n",
    "                compare_name = '%s %s %s %s' % (incon, ss, nom[frt], nom[sec])\n",
    "                # Saving stats in a DataFrame\n",
    "                col0 = pd.Series('%s' % (compare_name))  # string\n",
    "                temp_cur = pd.concat([col0, df_res], axis=1)\n",
    "                final_temp_acrosscondi = pd.concat([temp_cur, final_temp_acrosscondi], axis=0)\n",
    "\n",
    "                sec = sec + 1\n",
    "                c = c + 1\n",
    "            elif c >= lister[frt]:\n",
    "                # reset\n",
    "                c = 0\n",
    "                frt = frt+1\n",
    "                sec = frt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab363fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics RT : comparing correct to not-correct\n",
    "\n",
    "nom = ['RO', 'PI', 'YA', 'LR', 'FB', 'UD']\n",
    "\n",
    "num_of_tests = 2\n",
    "final_temp_acrosscondiTR = pd.DataFrame()\n",
    "\n",
    "incon_list = ['IC+EC', 'NC+NR']\n",
    "\n",
    "for incon in incon_list:\n",
    "    if incon == 'IC+EC':\n",
    "        inc1 = 'IC'\n",
    "        inc2 = 'EC'\n",
    "    elif incon == 'NC+NR':\n",
    "        inc1 = 'NC'\n",
    "        inc2 = 'NR'\n",
    "    \n",
    "    for ss in outer_name_list:\n",
    "        if ss == 'sub':\n",
    "            vec0 = df_long_totTR.vals_rot_RO_sub[(df_long_totTR.str_rot_RO_sub == inc1) | (df_long_totTR.str_rot_RO_sub == inc2)].to_numpy()\n",
    "            vec1 = df_long_totTR.vals_rot_PI_sub[(df_long_totTR.str_rot_PI_sub == inc1) | (df_long_totTR.str_rot_PI_sub == inc2)].to_numpy()\n",
    "            vec2 = df_long_totTR.vals_rot_YA_sub[(df_long_totTR.str_rot_YA_sub == inc1) | (df_long_totTR.str_rot_YA_sub == inc2)].to_numpy()\n",
    "            vec3 = df_long_totTR.vals_trans_LR_sub[(df_long_totTR.str_trans_LR_sub == inc1) | (df_long_totTR.str_trans_LR_sub == inc2)].to_numpy()\n",
    "            vec4 = df_long_totTR.vals_trans_FB_sub[(df_long_totTR.str_trans_FB_sub == inc1) | (df_long_totTR.str_trans_FB_sub == inc2)].to_numpy()\n",
    "            vec5 = df_long_totTR.vals_trans_UD_sub[(df_long_totTR.str_trans_UD_sub == inc1) | (df_long_totTR.str_trans_UD_sub == inc2)].to_numpy()  \n",
    "        elif ss == 'sup':\n",
    "            vec0 = df_long_totTR.vals_rot_RO_sup[(df_long_totTR.str_rot_RO_sup == inc1) | (df_long_totTR.str_rot_RO_sup == inc2)].to_numpy()\n",
    "            vec1 = df_long_totTR.vals_rot_PI_sup[(df_long_totTR.str_rot_PI_sup == inc1) | (df_long_totTR.str_rot_PI_sup == inc2)].to_numpy()\n",
    "            vec2 = df_long_totTR.vals_rot_YA_sup[(df_long_totTR.str_rot_YA_sup == inc1) | (df_long_totTR.str_rot_YA_sup == inc2)].to_numpy()\n",
    "            vec3 = df_long_totTR.vals_trans_LR_sup[(df_long_totTR.str_trans_LR_sup == inc1) | (df_long_totTR.str_trans_LR_sup == inc2)].to_numpy()\n",
    "            vec4 = df_long_totTR.vals_trans_FB_sup[(df_long_totTR.str_trans_FB_sup == inc1) | (df_long_totTR.str_trans_FB_sup == inc2)].to_numpy()\n",
    "            vec5 = df_long_totTR.vals_trans_UD_sup[(df_long_totTR.str_trans_UD_sup == inc1) | (df_long_totTR.str_trans_UD_sup == inc2)].to_numpy()\n",
    "            \n",
    "        vec_comp = [vec0, vec1, vec2, vec3, vec4, vec5]\n",
    "        \n",
    "        \n",
    "        # Statistics \n",
    "        lister = list(range(len(vec_comp)-1, 0, -1))\n",
    "        # print('lister : ', lister)\n",
    "        acc4res = len(lister)-1      # account for resets\n",
    "        tot = np.sum(lister)\n",
    "        # print('tot : ', tot)\n",
    "\n",
    "        frt = 0\n",
    "        sec = frt+1\n",
    "        c = 0\n",
    "        for i in range(tot+acc4res):\n",
    "            print('i : ', i)\n",
    "            if c < lister[frt]:\n",
    "\n",
    "                vecA = vec_comp[frt]\n",
    "                vecB = vec_comp[sec]\n",
    "                print('vecA : ', vecA)\n",
    "                print('vecB : ', vecB)\n",
    "\n",
    "                # Statistical tests\n",
    "                df_res = two_sample_stats(vecA, vecB, num_of_tests)\n",
    "                compare_name = '%s %s %s %s' % (incon, ss, nom[frt], nom[sec])\n",
    "                # Saving stats in a DataFrame\n",
    "                col0 = pd.Series('%s' % (compare_name))  # string\n",
    "                temp_cur = pd.concat([col0, df_res], axis=1)\n",
    "                final_temp_acrosscondiTR = pd.concat([temp_cur, final_temp_acrosscondiTR], axis=0)\n",
    "\n",
    "                sec = sec + 1\n",
    "                c = c + 1\n",
    "            elif c >= lister[frt]:\n",
    "                # reset\n",
    "                c = 0\n",
    "                frt = frt+1\n",
    "                sec = frt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4e8e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_temp_acrosscondi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fecb981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_temp_acrosscondiTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a350da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need rows where pval_1 and pval_2 are less than 0.0167 \n",
    "final_temp_acrosscondi[(final_temp_acrosscondi.pval_1 < 0.0167) & (final_temp_acrosscondi.pval_2 < 0.0167)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c165e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We only need rows where pval_1 and pval_2 are less than 0.0167 \n",
    "final_temp_acrosscondiTR[(final_temp_acrosscondiTR.pval_1 < 0.0167) & (final_temp_acrosscondiTR.pval_2 < 0.0167)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23068280",
   "metadata": {},
   "source": [
    "### Plotting count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon):\n",
    "    \n",
    "    vec0_str0 = 'RO ' * len(vec0_vals)\n",
    "    vec0_str = vec0_str0.split()\n",
    "\n",
    "    vec1_str0 = 'PI ' * len(vec1_vals)\n",
    "    vec1_str = vec1_str0.split()\n",
    "\n",
    "    vec2_str0 = 'YA ' * len(vec2_vals)\n",
    "    vec2_str = vec2_str0.split()\n",
    "\n",
    "    vec3_str0 = 'LR ' * len(vec3_vals)\n",
    "    vec3_str = vec3_str0.split()\n",
    "\n",
    "    vec4_str0 = 'FB ' * len(vec4_vals)\n",
    "    vec4_str = vec4_str0.split()\n",
    "\n",
    "    vec5_str0 = 'UD ' * len(vec5_vals)\n",
    "    vec5_str = vec5_str0.split()\n",
    "\n",
    "    # Plotting combined rotational and translation data\n",
    "    vec_comp_vals = pd.concat([vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals])\n",
    "    vec_comp_vals.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = make_a_properlist([vec0_str, vec1_str, vec2_str, vec3_str, vec4_str, vec5_str])\n",
    "    vec_comp_str = pd.Series(data)\n",
    "    vec_comp_str.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    a = incon+\" \"\n",
    "    data_res_type = a * len(vec_comp_str)\n",
    "    data_res_type = data_res_type.split()\n",
    "    vec_comp_res_type = pd.Series(data_res_type)\n",
    "    vec_comp_res_type.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    temp = pd.concat([vec_comp_str, vec_comp_vals, vec_comp_res_type], axis=1)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea961f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot of half the data\n",
    "# incon_list = ['IC', 'EC', 'NC', 'NR']\n",
    "incon_list = ['IC', 'NC']\n",
    "\n",
    "for ss in outer_name_list:\n",
    "    if ss == 'sub':\n",
    "        \n",
    "        condensed_df_sub = pd.DataFrame()\n",
    "\n",
    "        for incon in incon_list:\n",
    "            vec0_vals = df_long_tot.vals_rot_RO_sub[(df_long_tot.str_rot_RO_sub == incon)]\n",
    "            vec1_vals = df_long_tot.vals_rot_PI_sub[(df_long_tot.str_rot_PI_sub == incon)]\n",
    "            vec2_vals = df_long_tot.vals_rot_YA_sub[(df_long_tot.str_rot_YA_sub == incon)]\n",
    "            vec3_vals = df_long_tot.vals_trans_LR_sub[(df_long_tot.str_trans_LR_sub == incon)]\n",
    "            vec4_vals = df_long_tot.vals_trans_FB_sub[(df_long_tot.str_trans_FB_sub == incon)]\n",
    "            vec5_vals = df_long_tot.vals_trans_UD_sub[(df_long_tot.str_trans_UD_sub == incon)]\n",
    "            \n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            \n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_sub = pd.concat([condensed_df_sub, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_sub = condensed_df_sub.append(temp)\n",
    "            \n",
    "            print('shape of condensed_df_sub: ', condensed_df_sub.shape)\n",
    "            \n",
    "            condensed_df_sub.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_sub = condensed_df_sub.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "                \n",
    "    elif ss == 'sup':\n",
    "            \n",
    "        condensed_df_sup = pd.DataFrame()\n",
    "            \n",
    "        for incon in incon_list:\n",
    "            vec0_vals = df_long_tot.vals_rot_RO_sup[(df_long_tot.str_rot_RO_sup == incon)]\n",
    "            vec1_vals = df_long_tot.vals_rot_PI_sup[(df_long_tot.str_rot_PI_sup == incon)]\n",
    "            vec2_vals = df_long_tot.vals_rot_YA_sup[(df_long_tot.str_rot_YA_sup == incon)]\n",
    "            vec3_vals = df_long_tot.vals_trans_LR_sup[(df_long_tot.str_trans_LR_sup == incon)]\n",
    "            vec4_vals = df_long_tot.vals_trans_FB_sup[(df_long_tot.str_trans_FB_sup == incon)]\n",
    "            vec5_vals = df_long_tot.vals_trans_UD_sup[(df_long_tot.str_trans_UD_sup == incon)]\n",
    "\n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_sup = pd.concat([condensed_df_sup, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_sup = condensed_df_sup.append(temp)\n",
    "            \n",
    "            \n",
    "            condensed_df_sup.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_sup = condensed_df_sup.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3178a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "incon_list = ['IC+EC', 'NC+NR']\n",
    "\n",
    "for ss in outer_name_list:\n",
    "    if ss == 'sub':\n",
    "        \n",
    "        condensed_df_sub_2cat = pd.DataFrame()\n",
    "\n",
    "        for incon in incon_list:\n",
    "            if incon == 'IC+EC':\n",
    "                inc1 = 'IC'\n",
    "                inc2 = 'EC'\n",
    "            elif incon == 'NC+NR':\n",
    "                inc1 = 'NC'\n",
    "                inc2 = 'NR'\n",
    "\n",
    "            vec0_vals = df_long_tot.vals_rot_RO_sub[(df_long_tot.str_rot_RO_sub == inc1) | (df_long_tot.str_rot_RO_sub == inc2)]\n",
    "            vec1_vals = df_long_tot.vals_rot_PI_sub[(df_long_tot.str_rot_PI_sub == inc1) | (df_long_tot.str_rot_PI_sub == inc2)]\n",
    "            vec2_vals = df_long_tot.vals_rot_YA_sub[(df_long_tot.str_rot_YA_sub == inc1) | (df_long_tot.str_rot_YA_sub == inc2)]\n",
    "            vec3_vals = df_long_tot.vals_trans_LR_sub[(df_long_tot.str_trans_LR_sub == inc1) | (df_long_tot.str_trans_LR_sub == inc2)]\n",
    "            vec4_vals = df_long_tot.vals_trans_FB_sub[(df_long_tot.str_trans_FB_sub == inc1) | (df_long_tot.str_trans_FB_sub == inc2)]\n",
    "            vec5_vals = df_long_tot.vals_trans_UD_sub[(df_long_tot.str_trans_UD_sub == inc1) | (df_long_tot.str_trans_UD_sub == inc2)]\n",
    "            \n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            \n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_sub_2cat = pd.concat([condensed_df_sub_2cat, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_sub_2cat = condensed_df_sub_2cat.append(temp)\n",
    "            \n",
    "            print('shape of condensed_df_sub_2cat: ', condensed_df_sub_2cat.shape)\n",
    "            \n",
    "            condensed_df_sub_2cat.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_sub_2cat = condensed_df_sub_2cat.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "                \n",
    "    elif ss == 'sup':\n",
    "            \n",
    "        condensed_df_sup_2cat = pd.DataFrame()\n",
    "            \n",
    "        for incon in incon_list:\n",
    "            if incon == 'IC+EC':\n",
    "                inc1 = 'IC'\n",
    "                inc2 = 'EC'\n",
    "            elif incon == 'NC+NR':\n",
    "                inc1 = 'NC'\n",
    "                inc2 = 'NR'\n",
    "\n",
    "            vec0_vals = df_long_tot.vals_rot_RO_sup[(df_long_tot.str_rot_RO_sup == inc1) | (df_long_tot.str_rot_RO_sup == inc2)]\n",
    "            vec1_vals = df_long_tot.vals_rot_PI_sup[(df_long_tot.str_rot_PI_sup == inc1) | (df_long_tot.str_rot_PI_sup == inc2)]\n",
    "            vec2_vals = df_long_tot.vals_rot_YA_sup[(df_long_tot.str_rot_YA_sup == inc1) | (df_long_tot.str_rot_YA_sup == inc2)]\n",
    "            vec3_vals = df_long_tot.vals_trans_LR_sup[(df_long_tot.str_trans_LR_sup == inc1) | (df_long_tot.str_trans_LR_sup == inc2)]\n",
    "            vec4_vals = df_long_tot.vals_trans_FB_sup[(df_long_tot.str_trans_FB_sup == inc1) | (df_long_tot.str_trans_FB_sup == inc2)]\n",
    "            vec5_vals = df_long_tot.vals_trans_UD_sup[(df_long_tot.str_trans_UD_sup == inc1) | (df_long_tot.str_trans_UD_sup == inc2)]\n",
    "\n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_sup_2cat = pd.concat([condensed_df_sup_2cat, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_sup_2cat = condensed_df_sup_2cat.append(temp)\n",
    "            \n",
    "            \n",
    "            condensed_df_sup_2cat.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_sup_2cat = condensed_df_sup_2cat.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_df_sup_2cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec532686",
   "metadata": {},
   "source": [
    "### TR Plotting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0580660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of half the data\n",
    "# incon_list = ['IC', 'EC', 'NC', 'NR']\n",
    "incon_list = ['IC']\n",
    "\n",
    "\n",
    "for ss in outer_name_list:\n",
    "    if ss == 'sub':\n",
    "        \n",
    "        condensed_df_subTR = pd.DataFrame()\n",
    "\n",
    "        for incon in incon_list:\n",
    "            vec0_vals = df_long_totTR.vals_rot_RO_sub[(df_long_totTR.str_rot_RO_sub == incon)]\n",
    "            vec1_vals = df_long_totTR.vals_rot_PI_sub[(df_long_totTR.str_rot_PI_sub == incon)]\n",
    "            vec2_vals = df_long_totTR.vals_rot_YA_sub[(df_long_totTR.str_rot_YA_sub == incon)]\n",
    "            vec3_vals = df_long_totTR.vals_trans_LR_sub[(df_long_totTR.str_trans_LR_sub == incon)]\n",
    "            vec4_vals = df_long_totTR.vals_trans_FB_sub[(df_long_totTR.str_trans_FB_sub == incon)]\n",
    "            vec5_vals = df_long_totTR.vals_trans_UD_sub[(df_long_totTR.str_trans_UD_sub == incon)]\n",
    "            \n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            \n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_subTR = pd.concat([condensed_df_subTR, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_subTR = condensed_df_subTR.append(temp)\n",
    "            \n",
    "            print('shape of condensed_df_subTR: ', condensed_df_subTR.shape)\n",
    "            \n",
    "            condensed_df_subTR.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_subTR = condensed_df_subTR.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "                \n",
    "    elif ss == 'sup':\n",
    "            \n",
    "        condensed_df_supTR = pd.DataFrame()\n",
    "            \n",
    "        for incon in incon_list:\n",
    "            vec0_vals = df_long_totTR.vals_rot_RO_sup[(df_long_totTR.str_rot_RO_sup == incon)]\n",
    "            vec1_vals = df_long_totTR.vals_rot_PI_sup[(df_long_totTR.str_rot_PI_sup == incon)]\n",
    "            vec2_vals = df_long_totTR.vals_rot_YA_sup[(df_long_totTR.str_rot_YA_sup == incon)]\n",
    "            vec3_vals = df_long_totTR.vals_trans_LR_sup[(df_long_totTR.str_trans_LR_sup == incon)]\n",
    "            vec4_vals = df_long_totTR.vals_trans_FB_sup[(df_long_totTR.str_trans_FB_sup == incon)]\n",
    "            vec5_vals = df_long_totTR.vals_trans_UD_sup[(df_long_totTR.str_trans_UD_sup == incon)]\n",
    "\n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_supTR = pd.concat([condensed_df_supTR, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_supTR = condensed_df_supTR.append(temp)\n",
    "            \n",
    "            \n",
    "            condensed_df_supTR.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_supTR = condensed_df_supTR.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea17a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot : For time response it is irrelavant to plot time for when they never got it correct : 'NC+NR'\n",
    "incon_list = ['IC+EC']\n",
    "\n",
    "for ss in outer_name_list:\n",
    "    if ss == 'sub':\n",
    "        \n",
    "        condensed_df_subTR_2cat = pd.DataFrame()\n",
    "\n",
    "        for incon in incon_list:\n",
    "            if incon == 'IC+EC':\n",
    "                inc1 = 'IC'\n",
    "                inc2 = 'EC'\n",
    "            elif incon == 'NC+NR':\n",
    "                inc1 = 'NC'\n",
    "                inc2 = 'NR'\n",
    "\n",
    "            vec0_vals = df_long_totTR.vals_rot_RO_sub[(df_long_totTR.str_rot_RO_sub == inc1) | (df_long_totTR.str_rot_RO_sub == inc2)]\n",
    "            vec1_vals = df_long_totTR.vals_rot_PI_sub[(df_long_totTR.str_rot_PI_sub == inc1) | (df_long_totTR.str_rot_PI_sub == inc2)]\n",
    "            vec2_vals = df_long_totTR.vals_rot_YA_sub[(df_long_totTR.str_rot_YA_sub == inc1) | (df_long_totTR.str_rot_YA_sub == inc2)]\n",
    "            vec3_vals = df_long_totTR.vals_trans_LR_sub[(df_long_totTR.str_trans_LR_sub == inc1) | (df_long_totTR.str_trans_LR_sub == inc2)]\n",
    "            vec4_vals = df_long_totTR.vals_trans_FB_sub[(df_long_totTR.str_trans_FB_sub == inc1) | (df_long_totTR.str_trans_FB_sub == inc2)]\n",
    "            vec5_vals = df_long_totTR.vals_trans_UD_sub[(df_long_totTR.str_trans_UD_sub == inc1) | (df_long_totTR.str_trans_UD_sub == inc2)]\n",
    "            \n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            \n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_subTR_2cat = pd.concat([condensed_df_subTR_2cat, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_subTR_2cat = condensed_df_subTR_2cat.append(temp)\n",
    "            \n",
    "            print('shape of condensed_df_subTR_2cat: ', condensed_df_subTR_2cat.shape)\n",
    "            \n",
    "            condensed_df_subTR_2cat.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_subTR_2cat = condensed_df_subTR_2cat.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "                \n",
    "    elif ss == 'sup':\n",
    "            \n",
    "        condensed_df_supTR_2cat = pd.DataFrame()\n",
    "            \n",
    "        for incon in incon_list:\n",
    "            if incon == 'IC+EC':\n",
    "                inc1 = 'IC'\n",
    "                inc2 = 'EC'\n",
    "            elif incon == 'NC+NR':\n",
    "                inc1 = 'NC'\n",
    "                inc2 = 'NR'\n",
    "\n",
    "            vec0_vals = df_long_totTR.vals_rot_RO_sup[(df_long_totTR.str_rot_RO_sup == inc1) | (df_long_totTR.str_rot_RO_sup == inc2)]\n",
    "            vec1_vals = df_long_totTR.vals_rot_PI_sup[(df_long_totTR.str_rot_PI_sup == inc1) | (df_long_totTR.str_rot_PI_sup == inc2)]\n",
    "            vec2_vals = df_long_totTR.vals_rot_YA_sup[(df_long_totTR.str_rot_YA_sup == inc1) | (df_long_totTR.str_rot_YA_sup == inc2)]\n",
    "            vec3_vals = df_long_totTR.vals_trans_LR_sup[(df_long_totTR.str_trans_LR_sup == inc1) | (df_long_totTR.str_trans_LR_sup == inc2)]\n",
    "            vec4_vals = df_long_totTR.vals_trans_FB_sup[(df_long_totTR.str_trans_FB_sup == inc1) | (df_long_totTR.str_trans_FB_sup == inc2)]\n",
    "            vec5_vals = df_long_totTR.vals_trans_UD_sup[(df_long_totTR.str_trans_UD_sup == inc1) | (df_long_totTR.str_trans_UD_sup == inc2)]\n",
    "\n",
    "            temp = repeating_stuff(vec0_vals, vec1_vals, vec2_vals, vec3_vals, vec4_vals, vec5_vals, incon)\n",
    "            temp = temp.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)\n",
    "            \n",
    "            #condensed_df_supTR_2cat = pd.concat([condensed_df_supTR_2cat, temp], axis=0)\n",
    "            # OR\n",
    "            condensed_df_supTR_2cat = condensed_df_supTR_2cat.append(temp)\n",
    "            \n",
    "            \n",
    "            condensed_df_supTR_2cat.reset_index(drop=True, inplace=True)\n",
    "            condensed_df_supTR_2cat = condensed_df_supTR_2cat.rename({0: 'str', 1: 'vals', 2: 'res_type'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04faffe1",
   "metadata": {},
   "source": [
    "### Final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264372dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from textwrap import wrap\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(20,10))  # the right=sub, left=sup\n",
    "\n",
    "sns.set(font_scale = 2) # default is without style and palette\n",
    "#sns.color_palette(\"light:#90a4ae\", as_cmap=True)  # Greys_d, light:#5A9\n",
    "\n",
    "front_edge_color = \"#362d17\"  # '#5c7d83' #'#669999'#\n",
    "back_edge_color = \"#362d17\"  # black\n",
    "\n",
    "alpha = 0.8\n",
    "\n",
    "# ----------------------------\n",
    "# Summed normalized count\n",
    "# ----------------------------\n",
    "po = 0\n",
    "#sub: count\n",
    "# IC+EC and NC+NR\n",
    "oo = sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sub_2cat, ax=ax[po,0], ci=\"sd\", capsize=.1, estimator=np.sum, palette=\"light:#90a4ae\", errcolor=back_edge_color, linewidth=3, edgecolor=back_edge_color, alpha=alpha, linestyle='-')\n",
    "\n",
    "num_locations = len(condensed_df_sub_2cat)\n",
    "hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n",
    "for i, bar in enumerate(oo.patches):\n",
    "    if i % num_locations == 0:\n",
    "        hatch = next(hatches)\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# IC, NC\n",
    "sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sub, ax=ax[po,0], ci=\"sd\", capsize=.1, estimator=np.sum, palette=\"light:#90a4ae\", errcolor=front_edge_color, linewidth=3, edgecolor=front_edge_color, alpha=alpha, linestyle='-')\n",
    "\n",
    "ax[po,0].set(ylim=(0, 150))\n",
    "ax[po,0].set_ylabel(\"\\n\".join(wrap('Normalized count', 11)))  # left\n",
    "ax[po,0].set_xlabel('', fontsize=22)\n",
    "\n",
    "# ax[cou].set_yticks([])\n",
    "# Remove legend\n",
    "ax[po,0].legend([],[], frameon=False)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "# ax[po,0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "#sup: count\n",
    "# IC+EC and NC+NR\n",
    "oo = sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sup_2cat, ax=ax[po,1], ci=\"sd\", capsize=.1, estimator=np.sum, palette=\"light:#90a4ae\", errcolor=back_edge_color, linewidth=3, edgecolor=back_edge_color, alpha=alpha)\n",
    "\n",
    "num_locations = len(condensed_df_sub_2cat)\n",
    "hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n",
    "for i, bar in enumerate(oo.patches):\n",
    "    if i % num_locations == 0:\n",
    "        hatch = next(hatches)\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# IC, NC\n",
    "sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sup, ax=ax[po,1], ci=\"sd\", capsize=.1, estimator=np.sum, palette=\"light:#90a4ae\", errcolor=front_edge_color, linewidth=3, edgecolor=front_edge_color, alpha=alpha)\n",
    "\n",
    "ax[po,1].set(ylim=(0, 150))\n",
    "ax[po,1].set_ylabel('', fontsize=22)  # right\n",
    "ax[po,1].set_xlabel('', fontsize=22)\n",
    "\n",
    "# Remove legend\n",
    "ax[po,1].legend([],[], frameon=False)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "# ax[po,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "# ----------------------------\n",
    "\n",
    "# Lower tail of 95 percent confidence interval per axis\n",
    "ro_sub = condensed_df_sub_2cat.vals[(condensed_df_sub_2cat.str == 'RO')].to_numpy()\n",
    "ro_sup = condensed_df_sup_2cat.vals[(condensed_df_sup_2cat.str == 'RO')].to_numpy()\n",
    "pi_sub = condensed_df_sub_2cat.vals[(condensed_df_sub_2cat.str == 'PI')].to_numpy()\n",
    "pi_sup = condensed_df_sup_2cat.vals[(condensed_df_sup_2cat.str == 'PI')].to_numpy()\n",
    "ya_sub = condensed_df_sub_2cat.vals[(condensed_df_sub_2cat.str == 'YA')].to_numpy()\n",
    "ya_sup = condensed_df_sup_2cat.vals[(condensed_df_sup_2cat.str == 'YA')].to_numpy()\n",
    "lr_sub = condensed_df_sub_2cat.vals[(condensed_df_sub_2cat.str == 'LR')].to_numpy()\n",
    "lr_sup = condensed_df_sup_2cat.vals[(condensed_df_sup_2cat.str == 'LR')].to_numpy()\n",
    "fb_sub = condensed_df_sub_2cat.vals[(condensed_df_sub_2cat.str == 'FB')].to_numpy()\n",
    "fb_sup = condensed_df_sup_2cat.vals[(condensed_df_sup_2cat.str == 'FB')].to_numpy()\n",
    "ud_sub = condensed_df_sub_2cat.vals[(condensed_df_sub_2cat.str == 'UD')].to_numpy()\n",
    "ud_sup = condensed_df_sup_2cat.vals[(condensed_df_sup_2cat.str == 'UD')].to_numpy()\n",
    "\n",
    "# RO\n",
    "linestyle = '-'\n",
    "vec = make_a_properlist(np.concatenate((ro_sub, ro_sup), axis=0))\n",
    "mean_dat, lower_tail, upper_tail = confidence_interval(vec, desired_CI=0.95)\n",
    "ax[po,0].axhline(lower_tail, xmin=0, xmax=0.16, ls=linestyle, linewidth=3, color='r')\n",
    "ax[po,1].axhline(lower_tail, xmin=0, xmax=0.16, ls=linestyle, linewidth=3, color='r')\n",
    "\n",
    "# PI\n",
    "vec = make_a_properlist(np.concatenate((pi_sub, pi_sup), axis=0))\n",
    "mean_dat, lower_tail, upper_tail = confidence_interval(vec, desired_CI=0.95)\n",
    "ax[po,0].axhline(lower_tail, xmin=0.18, xmax=0.33, ls=linestyle, linewidth=3, color='r')\n",
    "ax[po,1].axhline(lower_tail, xmin=0.18, xmax=0.33, ls=linestyle, linewidth=3, color='r')\n",
    "\n",
    "# YA\n",
    "vec = make_a_properlist(np.concatenate((ya_sub, ya_sup), axis=0))\n",
    "mean_dat, lower_tail, upper_tail = confidence_interval(vec, desired_CI=0.95)\n",
    "ax[po,0].axhline(y=lower_tail, xmin=0.34, xmax=0.49, ls=linestyle, linewidth=3, color='r')\n",
    "ax[po,1].axhline(y=lower_tail, xmin=0.34, xmax=0.49, ls=linestyle, linewidth=3, color='r')\n",
    "\n",
    "# LR\n",
    "vec = make_a_properlist(np.concatenate((lr_sub, lr_sup), axis=0))\n",
    "mean_dat, lower_tail, upper_tail = confidence_interval(vec, desired_CI=0.95)\n",
    "ax[po,0].axhline(y=lower_tail, xmin=0.51, xmax=0.66, ls=linestyle, linewidth=3, color='r')\n",
    "ax[po,1].axhline(y=lower_tail, xmin=0.51, xmax=0.66, ls=linestyle, linewidth=3, color='r')\n",
    "\n",
    "# FB\n",
    "vec = make_a_properlist(np.concatenate((fb_sub, fb_sup), axis=0))\n",
    "mean_dat, lower_tail, upper_tail = confidence_interval(vec, desired_CI=0.95)\n",
    "ax[po,0].axhline(y=lower_tail, xmin=0.68, xmax=0.83, ls=linestyle, linewidth=3, color='r')\n",
    "ax[po,1].axhline(y=lower_tail, xmin=0.68, xmax=0.83, ls=linestyle, linewidth=3, color='r')\n",
    "\n",
    "# UD\n",
    "vec = make_a_properlist(np.concatenate((ud_sub, ud_sup), axis=0))\n",
    "mean_dat, lower_tail, upper_tail = confidence_interval(vec, desired_CI=0.95)\n",
    "ax[po,0].axhline(y=lower_tail, xmin=0.84, xmax=1.0, ls=linestyle, linewidth=3, color='r')\n",
    "ax[po,1].axhline(y=lower_tail, xmin=0.84, xmax=1.0, ls=linestyle, linewidth=3, color='r')\n",
    "\n",
    "# ----------------------------\n",
    "# Mean normalized count\n",
    "# ----------------------------\n",
    "po = 1\n",
    "#sub: count\n",
    "# IC+EC and NC+NR\n",
    "oo = sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sub_2cat, ax=ax[po,0], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=back_edge_color, linewidth=3, edgecolor=back_edge_color, alpha=alpha)\n",
    "\n",
    "num_locations = len(condensed_df_sub_2cat)\n",
    "hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n",
    "for i, bar in enumerate(oo.patches):\n",
    "    if i % num_locations == 0:\n",
    "        hatch = next(hatches)\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# IC, NC\n",
    "sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sub, ax=ax[po,0], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=front_edge_color, linewidth=3, edgecolor=front_edge_color, alpha=alpha)\n",
    "\n",
    "ax[po,0].set(ylim=(0, 12))\n",
    "ax[po,0].set_ylabel(\"\\n\".join(wrap('Normalized Mean count', 11)))  # left\n",
    "ax[po,0].set_xlabel('', fontsize=22)\n",
    "\n",
    "# Remove legend\n",
    "ax[po,0].legend([],[], frameon=False)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "# ax[po,0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# ----------------------------\n",
    "#sup: count\n",
    "# IC+EC and NC+NR\n",
    "oo = sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sup_2cat, ax=ax[po,1], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=back_edge_color, linewidth=3, edgecolor=back_edge_color, alpha=alpha)\n",
    "\n",
    "num_locations = len(condensed_df_sup_2cat)\n",
    "hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n",
    "for i, bar in enumerate(oo.patches):\n",
    "    if i % num_locations == 0:\n",
    "        hatch = next(hatches)\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# IC, NC\n",
    "sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_sup, ax=ax[po,1], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=front_edge_color, linewidth=3, edgecolor=front_edge_color, alpha=alpha)\n",
    "\n",
    "ax[po,1].set(ylim=(0, 12))\n",
    "ax[po,1].set_ylabel('', fontsize=22)  # right\n",
    "ax[po,1].set_xlabel('', fontsize=22)\n",
    "\n",
    "# Remove legend\n",
    "# ax[po,1].legend([],[], frameon=False)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "ax[po,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize=17)\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Mean RT\n",
    "# ----------------------------\n",
    "po = 2\n",
    "#sub: RT\n",
    "# IC+EC\n",
    "oo = sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_subTR_2cat, ax=ax[po,0], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=back_edge_color, linewidth=3, edgecolor=back_edge_color, alpha=alpha)\n",
    "\n",
    "num_locations = len(condensed_df_sub_2cat)\n",
    "hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n",
    "for i, bar in enumerate(oo.patches):\n",
    "    if i % num_locations == 0:\n",
    "        hatch = next(hatches)\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# IC\n",
    "sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_subTR, ax=ax[po,0], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=front_edge_color, linewidth=3, edgecolor=front_edge_color, alpha=alpha)\n",
    "\n",
    "ax[po,0].set(ylim=(0, 13))\n",
    "ax[po,0].set_ylabel(\"\\n\".join(wrap('Mean RT (s)', 11)))  # left\n",
    "ax[po,0].set_xlabel('sub', fontsize=22)\n",
    "\n",
    "# Remove legend\n",
    "ax[po,0].legend([],[], frameon=False)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "# ax[po,0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# ----------------------------\n",
    "#sup: RT\n",
    "# IC+EC\n",
    "oo = sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_supTR_2cat, ax=ax[po,1], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=back_edge_color, linewidth=3, edgecolor=back_edge_color, alpha=alpha)\n",
    "\n",
    "num_locations = len(condensed_df_sup_2cat)\n",
    "hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n",
    "for i, bar in enumerate(oo.patches):\n",
    "    if i % num_locations == 0:\n",
    "        hatch = next(hatches)\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# IC\n",
    "sns.barplot(x=\"str\", y=\"vals\", hue=\"res_type\", data=condensed_df_supTR, ax=ax[po,1], ci=\"sd\", capsize=.1, estimator=np.mean, palette=\"light:#90a4ae\", errcolor=front_edge_color, linewidth=3, edgecolor=front_edge_color, alpha=alpha)\n",
    "\n",
    "ax[po,1].set(ylim=(0, 13))\n",
    "ax[po,1].set_ylabel('', fontsize=22)  # right\n",
    "ax[po,1].set_xlabel('sup', fontsize=22)\n",
    "\n",
    "# Remove legend\n",
    "ax[po,1].legend([],[], frameon=False)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "# ax[po,1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "# ----------------------------  \n",
    "\n",
    "\n",
    "plt.xticks(fontsize=22)\n",
    "\n",
    "plt.savefig('Final_count_TR_rot_trans.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989bf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
