-----------------
2 Methods
-----------------

The rotational and translational SD motion detection experiments were identically designed such that the resulting SD dataset would be in a standard format.  The following experimental parameters were the same for both experiments: experimental stimuli conditions, number of randomized trials per experiment, timeline of experimental events per trial, experimental protocol, motion simulation system.  The classification experiments required that five key modeling parameters be evaluate: number of features, model type, dataset conditions, feature type, semi-supervised label type. Model, feature, and semi-supervised label type were defined using human movement and SD domain specific information.

2.1 Motion detection experiment

In order to create a diverse dataset of vestibular and proprioceptive SD response, percpetual response was measured using a 3x3 block design testing a randomized combination of angular or linear axis motion, axial direction, and speed.  32 total participants participated, in both experiments, receiving the same experimental instructions and protocol while using the motion simulator.

2.1.1 Experimental design and timeline events

The axis experimental conditon had three parameters, cabin movements for rotation were roll, pitch, and yaw, and translation incuded left/right, forward/backward and up/down.  In addition, minuscule sinusoidal vibrational noise, 1-2cm in amplitude, was added to the non-stimulated axes to mask the sound of the motor for the selected stimulus.  Due to the fact that vibrational noise was present, participants were exposed to a more realistic aviation environment.  Furthermore, the additional vibration helped to reduce movement detection thresholds such that the task was realistically challenging (Chaudhuri et al, 2013).  The axial direction experimental condition had two paramters denoting positive and negative direction.  Figure 1A depicts both axis and axial direction convention for both rotational and translational experiments.  Finally, the speed experimental conditon had two parameters, a slow near sub-threshold (sub) speed where motion is difficult to detect and a fast near supra-threshold (sup) speed where motion detection is apparent.  The speed parameters required special selection such that values would be in alignment with motion detection thresholds and accommodate the motion constraints of the simulation system.  For both rotational and translation experiments, a range of sub and sup speed values were selected from motion detection literature (Previc et al, 2004; Melvill et al, 1978; Crane et al, 2016).  A calibration phase was conducted with 23 naive participants, where the literature speed values were tested using the motion simulator system.  Calibration phase participant’s sat naturally in the simulator and verbally reported which direction they believed that they were moving directly after randomized motion stimulation.  For the rotational experiment, the chosen sub and sup speed that reported the largest number of correct responses was 0.5 Hz (deg/s) and 1.25 Hz (deg/s) respectively.  Similarly for the translational experiment, the chosen sub and sup speed was 3.75 Hz (cm/s) and 15 Hz (cm/s) respectively.  Method and procedure for threshold selection are detailed in Supplementary Materials.
Figure 1: The grey Cartesian coordinate frame in Figure 1A represents the simulator cabin, the cabin could move in both rotation (Roll, Pitch, Yaw) and translation (Left/Right, Forward/Backward, Up/Down) via the input stimulus and/or participant control. The black outlined squares and circles in Figure 1A denote positive directional movement (RollP, PitchP, YawP, Right, Forward, Down), where squares and circles correspond to rotational and translation movement respectively. Non-outlined squares and circles indicate negative directional movement (RollN, PitchN, YawN, Left, Backward, Up).  Figure 1B shows the mapping of participant’s joystick movements to the cabin movement.  Figure 1C denotes the experimental event timeline where each trial consisted of four phases:  (A) motion stimulation of the cabin with a smoothed ramp forcing function, (B) participant motion detection and afterwards active control, (C) cabin reinitialization to the initial orientation or position, (D) cabin and participant at rest.  The blue line denotes the ramp forcing function that actively perturbed the cabin, and red line denotes the participant's movements to counteract the perturbation after motion detection at T1 seconds;  the term T1 implies that the reaction time varied per trial.  The green line during phase c denotes automatic reinitialization of the cabin, and grey line during phase d denotes a rest period without any motion.  

A single trial was composed of four different phases, as denoted by the timeline in Figure 1C, where participants were tasked to respond to specific visual and vestibular stimuli per phase.  During both phase A and B, participants could move the simulator using the joystick in any of the rotational or translational axes to counteract the perturbation. 

    • Phase A Detection:  A smoothed ramp forcing function, where the rate of displacement was unknown to the participants, slowly and continuously perturbed one of the three rotational or translational axes of the simulator cabin at a sub or sup rate.  During phase A participants were tasked to perform "initial detection", which consisted of identifying the axis and direction of the felt perturbation and manipulating an aviation joystick (Thrustmaster Hotas Warthog joystick), shown in Figure 1B, in the opposite direction of the stimuli.  Participants had 15-20s to detect motion depending on the condition, denoted by T1 in Figure 1C, which corresponded to the cabin reaching the maximum allowed cabin displacement.  T1 was different for every axis and experiment because sub and sup rates were different for each experiment and the physical cabin displacement range was different for each axis.  In particular, the rotational experiment had slightly longer stimulation times than the translational experiment because the sub and sup rates were slower and the available cabin displacement in the roll, pitch, yaw orientations were larger than the available translational displacement ranges.  If participants did not respond within T1s during phase A, the cabin automatically displaced along one of the three axes as the ramp function increased until it reached T1s, where upon the ramp function maintained a zero slope causing the cabin to remain stationary for 2s.

    • Phase B Active Control: If participants responded within T1 seconds during phase A, phase B active control began and they had 15s to maintain the simulator orientation or position stably at the initial location by counteracting the perturbation.  No visual stimulation was present, thus participants could only rely upon vestibular and proprioceptive cues.

    • Phase C Reintialization: A red dot appeared on the screen instructing participants to release the joystick and rest, while the cabin automatically returned to the initial starting location in 10s. 

    • Phase D Rest: The cabin remained stationary at the starting location for 5s in order to avoid possible over stimulation or after effects.

Figure 1C shows two trajectories, when the participant detected and did not respond, demonstrating 
experimental phases and trial length were dependant upon participant response.  The shortest and longest length trial was approximately 32s and 50s respectively.  The shortest length trial would occur if T1=15s and the participant immediately responsed (2s+15s+10s+5s) or did not respond  (T1=15s+2s+10s+5s), the longest length trial would occur if T1=20s where the participant responded just before T1 equaled 20s (19.9s+15s+10s+5s).

Both experiments administered 42 trials, 12 familiarization practice and 30 experimental trials.  During the familiarization practice phase, unique experimental condition combinations were given where each of the 3 axes were stimulated in negative or positive directions at sub or sup speeds.  Similarly, the experimental phase consisted of 30 randomized trials, such that 15 trials with unique experimental conditions were repeated twice; 5 direction-speed conditions (negative sup, negative sub, no-movement, positive sup, positive sub) for each of the 3 axes (roll/lateral, pitch/longitudinal, yaw/vertical).  No-movement trials were included as sham trials to encourage participants to remain active.

2.1.2 Participants

18 and 14 healthy volunteers with normal or corrected vision, and no particular flight experience performed the rotational and translational near sub-threshold tasks (males and females, 32±10 SD years old): 4 of the 32 participants reported having novice time-limited (45 minutes, 2 hours, 40 hours, 45 hours) piloting experiences. 4 of the 18 rotational and 4 of the 14 translational participants were over the age of 40. The participants that performed the rotational experiment were not the same as participants that performed the translational experiment. Therefore, there were no confounds due to experimental ordering, learning, carryover, or fatigue. The same participant population, university students and personal, were used for both experiments therefore it is likely that both experimental populations were similar. 


2.1.3 Experimental protocol and motion simulation system

The experiment took approximately 90 minutes and consisted of four sections: (1) arrival/ questionnaires/ instruction, (2) familiarization, (3) active control of rotational or translational stimulation, (4) questionnaire/discussion.  After describing the experimental task and the completion of the questionnaires, participants were securely installed, using the safety harness and communication headphones, as shown in Figure 2. They were asked to moderately move the joystick in one axis direction at a time while compensating the unknown perturbation.  Participants were reminded to maintain the cabin at the initial trial position or orientation by compensating the motion stimulus.  The reaction time and/or strategy that participants adopted were chosen by the participants, no instruction was given regarding response quickness or accuracy.  In order to replicate a realistic flight scenario, participants were free to move their head and body, looking and/or fixating where they wished, as long as it did not interfere with the task.  Once the participant was installed in the cabin, the cabin door was closed and all communication between the participant and experimenter were performed via a camera interface system which facilitated two-way auditory visual communication. The physical well-being of the participants were monitored, the experiment ended if participants showed signs of physical illness.

The motion simulation system, that provided sensory stimulation, consisted of a 6-degree-of-freedom position controlled KUKA-based motion simulator system (KR 500-3 MT adapted by BEC GmbH motion simulators, KUKA Roboter GmbH, Germany) and a closed-network of three independent workstations (Denquin et al, 2021; Landrieu et al, 2017; Bellmann et al, 2011).  Figure 2 shows the interior and exterior of the simulation system, data was transfered between the KUKA and Workstations at 250Hz on a private UDP protocol network.  Workstation 1 and 3 were located in another room, where workstation 1 generated motion for the KUKA robot using a Matlab/Simulink control interface program.  Workstation 2 was fixed to the simulator cabin, it administered the red dot or black visual screen and registered joystick motion.  Workstation 3, using Labiew, served as the experimenter user control interface to start and stop the experiment, and collect experimental data without causing information delays between the workstations.

-------------------------------

2.2 SD Classification

Eight semi-supervised classification models were compared to classify the presence of perceived disorientation (SD), per trial across axis and speed conditions.  The eight models include both decision tree and optimization function driven algorithms: Stochastic Gradient Descent (SGD), Linear Discriminant Analysis (LDA), Random Forest (RF), Gradient Boosting Classifier (GBC), Decision Tree (DT), Two-layer Multilayer perceptron (MLP), Gaussian Naive Bayes (GNB), optimized Support Vector Machine (NuSVC).  Multiple models were compared in order to understand which types of predictive models best identified trends for the piloting task, for various experimental conditions.

2.2.1 Semi-supervised SD label construction

Three labels for SD were constructed by using the detection response profile, the labels were used to evaluate how the definition of perceptual disorientation could influence disorientation prediction. The first label, called lenient, allowed for mistakes to be initially made; Categories IC and EC are considered as non-SD state and unsuccessful detection responses (Category NC and NR) were considered as SD state.  The second label, called strict, did not allow for initial errors; initial successful detection response (Category IC) was considered as non-SD state and Categories EC, NC, and NR were considered as SD state.  For both binary labels vectors, a value of 0 was assigned to each trial where no-SD occurred and 1 was assigned to each trial where SD occurred.  Finally, the third label, called complex, categorized the level of disorientation based on a range of performed mistakes.   Initial successful detection response (Category IC) was considered as non-SD state, mild-SD state was considered to be Category EC where the response was eventually correct, and incorrect detection responses (Category NC and NR) were considered as SD state.  This multi-label vector assigned 0, 1, and 2 to no-SD,  mild-SD, and SD trials, respectively.

2.2.2 Feature construction

Features refer to the unique types of data the participant generated during each experimental trial.  We used participant joystick movement, a non-invasive measure containing real-time piloting behavior, and transformed the joystick measure to decouple known human motion control function.  It is known that human motion control involves coordinating position, velocity, and acceleration information in order to produce smooth motor behavior (citation of human motor).  Many works model smooth human motor control function using a linear combination of position, velocity, and acceleration information (citation).  Therefore, instead of only using the joystick measure as the only feature, we used this domain-specific modeling information and decoupled the joystick measure into position, velocity, acceleration, and frequency features.  By organizing the features in this manner, we not only obtain a predictive SD model but we can rank the importance of which types of human motor movements correlate with spatial disorientation.

Five features were used for model construction and predictive testing: (1) joystick signal (velocity control joystick), (2) 1st derivative of the joystick signal (human movement metric : acceleration), (3) 2nd derivative of the joystick signal (human movement metric : jerk), (4) frequency response of joystick position via FFT  (control theory metric : human-in-the-loop), (5) frequency of joystick (signal processing metric : estimate the period of the signal), (6) frequency of joystick (bandwidth cutoff/0.3 decibel drop of the frequency response of joystick via FFT (control theory metric : human-in-the-loop)).  The entire joystick movement traced from the start to the end of the trial was used for SD prediction.  Trials were at least 16 seconds long, and each trial length was set to the maximum trial data point length.  Interpolation was used to resize each trial with differing time length, via the python interp1d function.  Joystick data per trial for each participant was stacked into the feature matrix, 25% of the matrix and the corresponding label was “held-out”/not included in the construction of the predictive model. The excluded 25% of the data was used to test the predictive capability of the eight models, trained with both individual and all feature types.  Please see the appendix section for a detailed description of the classification pipeline for predicting SD.